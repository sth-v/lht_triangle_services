# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: query_root
    mutation: mutation_root
    subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
    "refresh the cache entry"
    refresh: Boolean! = false,
    "measured in seconds"
    ttl: Int! = 60
) on QUERY

"A union of all types that use the @key directive"
union _Entity = buffgeom_objects | geometry_attributes | lc_properties | lht_ceiling_panels

type _Service {
    "SDL representation of schema"
    sdl: String!
}

"columns and relationships of \"_enumtable.role\""
type _enumtable_role {
    comment: String
    "An array relationship"
    users(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): [_enumtable_users!]!
    "An aggregate relationship"
    users_aggregate(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): _enumtable_users_aggregate!
    value: String!
}

"aggregated selection of \"_enumtable.role\""
type _enumtable_role_aggregate {
    aggregate: _enumtable_role_aggregate_fields
    nodes: [_enumtable_role!]!
}

"aggregate fields of \"_enumtable.role\""
type _enumtable_role_aggregate_fields {
    count(columns: [_enumtable_role_select_column!], distinct: Boolean): Int!
    max: _enumtable_role_max_fields
    min: _enumtable_role_min_fields
}

"aggregate max on columns"
type _enumtable_role_max_fields {
    comment: String
    value: String
}

"aggregate min on columns"
type _enumtable_role_min_fields {
    comment: String
    value: String
}

"response of any mutation on the table \"_enumtable.role\""
type _enumtable_role_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [_enumtable_role!]!
}

"columns and relationships of \"_enumtable.users\""
type _enumtable_users {
    id: Int!
    name: String!
    type: _enumtable_role_enum!
}

"aggregated selection of \"_enumtable.users\""
type _enumtable_users_aggregate {
    aggregate: _enumtable_users_aggregate_fields
    nodes: [_enumtable_users!]!
}

"aggregate fields of \"_enumtable.users\""
type _enumtable_users_aggregate_fields {
    avg: _enumtable_users_avg_fields
    count(columns: [_enumtable_users_select_column!], distinct: Boolean): Int!
    max: _enumtable_users_max_fields
    min: _enumtable_users_min_fields
    stddev: _enumtable_users_stddev_fields
    stddev_pop: _enumtable_users_stddev_pop_fields
    stddev_samp: _enumtable_users_stddev_samp_fields
    sum: _enumtable_users_sum_fields
    var_pop: _enumtable_users_var_pop_fields
    var_samp: _enumtable_users_var_samp_fields
    variance: _enumtable_users_variance_fields
}

"aggregate avg on columns"
type _enumtable_users_avg_fields {
    id: Float
}

"aggregate max on columns"
type _enumtable_users_max_fields {
    id: Int
    name: String
}

"aggregate min on columns"
type _enumtable_users_min_fields {
    id: Int
    name: String
}

"response of any mutation on the table \"_enumtable.users\""
type _enumtable_users_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [_enumtable_users!]!
}

"aggregate stddev on columns"
type _enumtable_users_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type _enumtable_users_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type _enumtable_users_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type _enumtable_users_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type _enumtable_users_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type _enumtable_users_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type _enumtable_users_variance_fields {
    id: Float
}

"geometry fields"
type buffgeom_objects {
    "An object relationship"
    attributes: geometry_attributes
    castShadow: Boolean!
    children(
        "JSON select path"
        path: String
    ): jsonb
    geometry: uuid!
    layers: Int!
    material: uuid!
    matrix(
        "JSON select path"
        path: String
    ): jsonb!
    name: String
    receiveShadow: Boolean!
    type: String!
    userData(
        "JSON select path"
        path: String
    ): jsonb
    uuid: uuid!
}

"aggregated selection of \"buffgeom.objects\""
type buffgeom_objects_aggregate {
    aggregate: buffgeom_objects_aggregate_fields
    nodes: [buffgeom_objects!]!
}

"aggregate fields of \"buffgeom.objects\""
type buffgeom_objects_aggregate_fields {
    avg: buffgeom_objects_avg_fields
    count(columns: [buffgeom_objects_select_column!], distinct: Boolean): Int!
    max: buffgeom_objects_max_fields
    min: buffgeom_objects_min_fields
    stddev: buffgeom_objects_stddev_fields
    stddev_pop: buffgeom_objects_stddev_pop_fields
    stddev_samp: buffgeom_objects_stddev_samp_fields
    sum: buffgeom_objects_sum_fields
    var_pop: buffgeom_objects_var_pop_fields
    var_samp: buffgeom_objects_var_samp_fields
    variance: buffgeom_objects_variance_fields
}

"aggregate avg on columns"
type buffgeom_objects_avg_fields {
    layers: Float
}

"aggregate max on columns"
type buffgeom_objects_max_fields {
    geometry: uuid
    layers: Int
    material: uuid
    name: String
    type: String
    uuid: uuid
}

"aggregate min on columns"
type buffgeom_objects_min_fields {
    geometry: uuid
    layers: Int
    material: uuid
    name: String
    type: String
    uuid: uuid
}

"response of any mutation on the table \"buffgeom.objects\""
type buffgeom_objects_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [buffgeom_objects!]!
}

"aggregate stddev on columns"
type buffgeom_objects_stddev_fields {
    layers: Float
}

"aggregate stddev_pop on columns"
type buffgeom_objects_stddev_pop_fields {
    layers: Float
}

"aggregate stddev_samp on columns"
type buffgeom_objects_stddev_samp_fields {
    layers: Float
}

"aggregate sum on columns"
type buffgeom_objects_sum_fields {
    layers: Int
}

"aggregate var_pop on columns"
type buffgeom_objects_var_pop_fields {
    layers: Float
}

"aggregate var_samp on columns"
type buffgeom_objects_var_samp_fields {
    layers: Float
}

"aggregate variance on columns"
type buffgeom_objects_variance_fields {
    layers: Float
}

"attractive"
type geometry_attributes {
    index(
        "JSON select path"
        path: String
    ): jsonb
    normal(
        "JSON select path"
        path: String
    ): jsonb
    position(
        "JSON select path"
        path: String
    ): jsonb
    type: String!
    uuid: uuid!
    uv(
        "JSON select path"
        path: String
    ): jsonb
}

"aggregated selection of \"buffgeom.attributes\""
type geometry_attributes_aggregate {
    aggregate: geometry_attributes_aggregate_fields
    nodes: [geometry_attributes!]!
}

"aggregate fields of \"buffgeom.attributes\""
type geometry_attributes_aggregate_fields {
    count(columns: [geometry_attributes_select_column!], distinct: Boolean): Int!
    max: geometry_attributes_max_fields
    min: geometry_attributes_min_fields
}

"aggregate max on columns"
type geometry_attributes_max_fields {
    type: String
    uuid: uuid
}

"aggregate min on columns"
type geometry_attributes_min_fields {
    type: String
    uuid: uuid
}

"response of any mutation on the table \"buffgeom.attributes\""
type geometry_attributes_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [geometry_attributes!]!
}

"columns and relationships of \"lht_ceiling.properties\""
type lc_properties {
    id: Int!
    part: String
    sss: Int!
    stage: String
    status: String!
    subtype: String!
    type: String!
    uuid: uuid!
    zone: String!
}

"aggregated selection of \"lht_ceiling.properties\""
type lc_properties_aggregate {
    aggregate: lc_properties_aggregate_fields
    nodes: [lc_properties!]!
}

"aggregate fields of \"lht_ceiling.properties\""
type lc_properties_aggregate_fields {
    avg: lc_properties_avg_fields
    count(columns: [lc_properties_select_column!], distinct: Boolean): Int!
    max: lc_properties_max_fields
    min: lc_properties_min_fields
    stddev: lc_properties_stddev_fields
    stddev_pop: lc_properties_stddev_pop_fields
    stddev_samp: lc_properties_stddev_samp_fields
    sum: lc_properties_sum_fields
    var_pop: lc_properties_var_pop_fields
    var_samp: lc_properties_var_samp_fields
    variance: lc_properties_variance_fields
}

"aggregate avg on columns"
type lc_properties_avg_fields {
    id: Float
    sss: Float
}

"aggregate max on columns"
type lc_properties_max_fields {
    id: Int
    part: String
    sss: Int
    stage: String
    status: String
    subtype: String
    type: String
    uuid: uuid
    zone: String
}

"aggregate min on columns"
type lc_properties_min_fields {
    id: Int
    part: String
    sss: Int
    stage: String
    status: String
    subtype: String
    type: String
    uuid: uuid
    zone: String
}

"response of any mutation on the table \"lht_ceiling.properties\""
type lc_properties_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lc_properties!]!
}

"aggregate stddev on columns"
type lc_properties_stddev_fields {
    id: Float
    sss: Float
}

"aggregate stddev_pop on columns"
type lc_properties_stddev_pop_fields {
    id: Float
    sss: Float
}

"aggregate stddev_samp on columns"
type lc_properties_stddev_samp_fields {
    id: Float
    sss: Float
}

"aggregate sum on columns"
type lc_properties_sum_fields {
    id: Int
    sss: Int
}

"aggregate var_pop on columns"
type lc_properties_var_pop_fields {
    id: Float
    sss: Float
}

"aggregate var_samp on columns"
type lc_properties_var_samp_fields {
    id: Float
    sss: Float
}

"aggregate variance on columns"
type lc_properties_variance_fields {
    id: Float
    sss: Float
}

"columns and relationships of \"lht_ceiling.panels\""
type lht_ceiling_panels {
    centroid(
        "JSON select path"
        path: String
    ): jsonb
    cutted: Boolean
    "An object relationship"
    dtype: lht_ceiling_type_marks
    extra: Boolean
    floor: String!
    id: Int!
    mark: String
    mask: Boolean
    matrix(
        "JSON select path"
        path: String
    ): jsonb
    outside: Boolean
    points(
        "JSON select path"
        path: String
    ): jsonb
    stage: String
    stripe: Int
    subtype: Int!
    tag: String!
    updated_at: timestamptz!
    uuid: uuid!
    x: numeric!
    y: numeric!
}

"aggregated selection of \"lht_ceiling.panels\""
type lht_ceiling_panels_aggregate {
    aggregate: lht_ceiling_panels_aggregate_fields
    nodes: [lht_ceiling_panels!]!
}

"aggregate fields of \"lht_ceiling.panels\""
type lht_ceiling_panels_aggregate_fields {
    avg: lht_ceiling_panels_avg_fields
    count(columns: [lht_ceiling_panels_select_column!], distinct: Boolean): Int!
    max: lht_ceiling_panels_max_fields
    min: lht_ceiling_panels_min_fields
    stddev: lht_ceiling_panels_stddev_fields
    stddev_pop: lht_ceiling_panels_stddev_pop_fields
    stddev_samp: lht_ceiling_panels_stddev_samp_fields
    sum: lht_ceiling_panels_sum_fields
    var_pop: lht_ceiling_panels_var_pop_fields
    var_samp: lht_ceiling_panels_var_samp_fields
    variance: lht_ceiling_panels_variance_fields
}

"aggregate avg on columns"
type lht_ceiling_panels_avg_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate max on columns"
type lht_ceiling_panels_max_fields {
    floor: String
    id: Int
    mark: String
    stage: String
    stripe: Int
    subtype: Int
    tag: String
    updated_at: timestamptz
    uuid: uuid
    x: numeric
    y: numeric
}

"aggregate min on columns"
type lht_ceiling_panels_min_fields {
    floor: String
    id: Int
    mark: String
    stage: String
    stripe: Int
    subtype: Int
    tag: String
    updated_at: timestamptz
    uuid: uuid
    x: numeric
    y: numeric
}

"response of any mutation on the table \"lht_ceiling.panels\""
type lht_ceiling_panels_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_ceiling_panels!]!
}

"aggregate stddev on columns"
type lht_ceiling_panels_stddev_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate stddev_pop on columns"
type lht_ceiling_panels_stddev_pop_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate stddev_samp on columns"
type lht_ceiling_panels_stddev_samp_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate sum on columns"
type lht_ceiling_panels_sum_fields {
    id: Int
    stripe: Int
    subtype: Int
    x: numeric
    y: numeric
}

"aggregate var_pop on columns"
type lht_ceiling_panels_var_pop_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate var_samp on columns"
type lht_ceiling_panels_var_samp_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"aggregate variance on columns"
type lht_ceiling_panels_variance_fields {
    id: Float
    stripe: Float
    subtype: Float
    x: Float
    y: Float
}

"columns and relationships of \"lht_ceiling.type_marks\""
type lht_ceiling_type_marks {
    floor: String!
    modify: timestamptz!
    tag: String!
    uuid: uuid!
    x: numeric!
    y: numeric!
    z: numeric!
}

"aggregated selection of \"lht_ceiling.type_marks\""
type lht_ceiling_type_marks_aggregate {
    aggregate: lht_ceiling_type_marks_aggregate_fields
    nodes: [lht_ceiling_type_marks!]!
}

"aggregate fields of \"lht_ceiling.type_marks\""
type lht_ceiling_type_marks_aggregate_fields {
    avg: lht_ceiling_type_marks_avg_fields
    count(columns: [lht_ceiling_type_marks_select_column!], distinct: Boolean): Int!
    max: lht_ceiling_type_marks_max_fields
    min: lht_ceiling_type_marks_min_fields
    stddev: lht_ceiling_type_marks_stddev_fields
    stddev_pop: lht_ceiling_type_marks_stddev_pop_fields
    stddev_samp: lht_ceiling_type_marks_stddev_samp_fields
    sum: lht_ceiling_type_marks_sum_fields
    var_pop: lht_ceiling_type_marks_var_pop_fields
    var_samp: lht_ceiling_type_marks_var_samp_fields
    variance: lht_ceiling_type_marks_variance_fields
}

"aggregate avg on columns"
type lht_ceiling_type_marks_avg_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate max on columns"
type lht_ceiling_type_marks_max_fields {
    floor: String
    modify: timestamptz
    tag: String
    uuid: uuid
    x: numeric
    y: numeric
    z: numeric
}

"aggregate min on columns"
type lht_ceiling_type_marks_min_fields {
    floor: String
    modify: timestamptz
    tag: String
    uuid: uuid
    x: numeric
    y: numeric
    z: numeric
}

"response of any mutation on the table \"lht_ceiling.type_marks\""
type lht_ceiling_type_marks_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_ceiling_type_marks!]!
}

"aggregate stddev on columns"
type lht_ceiling_type_marks_stddev_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_pop on columns"
type lht_ceiling_type_marks_stddev_pop_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate stddev_samp on columns"
type lht_ceiling_type_marks_stddev_samp_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate sum on columns"
type lht_ceiling_type_marks_sum_fields {
    x: numeric
    y: numeric
    z: numeric
}

"aggregate var_pop on columns"
type lht_ceiling_type_marks_var_pop_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate var_samp on columns"
type lht_ceiling_type_marks_var_samp_fields {
    x: Float
    y: Float
    z: Float
}

"aggregate variance on columns"
type lht_ceiling_type_marks_variance_fields {
    x: Float
    y: Float
    z: Float
}

"columns and relationships of \"lht_triangles.connectors\""
type lht_triangles_connectors {
    "An array relationship"
    contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "An aggregate relationship"
    contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    from: String
    name: String!
    offset: numeric
    production: String
    type: String
}

"aggregated selection of \"lht_triangles.connectors\""
type lht_triangles_connectors_aggregate {
    aggregate: lht_triangles_connectors_aggregate_fields
    nodes: [lht_triangles_connectors!]!
}

"aggregate fields of \"lht_triangles.connectors\""
type lht_triangles_connectors_aggregate_fields {
    avg: lht_triangles_connectors_avg_fields
    count(columns: [lht_triangles_connectors_select_column!], distinct: Boolean): Int!
    max: lht_triangles_connectors_max_fields
    min: lht_triangles_connectors_min_fields
    stddev: lht_triangles_connectors_stddev_fields
    stddev_pop: lht_triangles_connectors_stddev_pop_fields
    stddev_samp: lht_triangles_connectors_stddev_samp_fields
    sum: lht_triangles_connectors_sum_fields
    var_pop: lht_triangles_connectors_var_pop_fields
    var_samp: lht_triangles_connectors_var_samp_fields
    variance: lht_triangles_connectors_variance_fields
}

"aggregate avg on columns"
type lht_triangles_connectors_avg_fields {
    offset: Float
}

"aggregate max on columns"
type lht_triangles_connectors_max_fields {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"aggregate min on columns"
type lht_triangles_connectors_min_fields {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"response of any mutation on the table \"lht_triangles.connectors\""
type lht_triangles_connectors_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_connectors!]!
}

"aggregate stddev on columns"
type lht_triangles_connectors_stddev_fields {
    offset: Float
}

"aggregate stddev_pop on columns"
type lht_triangles_connectors_stddev_pop_fields {
    offset: Float
}

"aggregate stddev_samp on columns"
type lht_triangles_connectors_stddev_samp_fields {
    offset: Float
}

"aggregate sum on columns"
type lht_triangles_connectors_sum_fields {
    offset: numeric
}

"aggregate var_pop on columns"
type lht_triangles_connectors_var_pop_fields {
    offset: Float
}

"aggregate var_samp on columns"
type lht_triangles_connectors_var_samp_fields {
    offset: Float
}

"aggregate variance on columns"
type lht_triangles_connectors_variance_fields {
    offset: Float
}

"columns and relationships of \"lht_triangles.contours\""
type lht_triangles_contours {
    "An object relationship"
    connector: lht_triangles_connectors
    curve(
        "JSON select path"
        path: String
    ): jsonb
    detail: name
    floor: lht_triangles_floors_enum
    "An object relationship"
    floorByFloor: lht_triangles_floors
    uuid: uuid!
}

"aggregated selection of \"lht_triangles.contours\""
type lht_triangles_contours_aggregate {
    aggregate: lht_triangles_contours_aggregate_fields
    nodes: [lht_triangles_contours!]!
}

"aggregate fields of \"lht_triangles.contours\""
type lht_triangles_contours_aggregate_fields {
    count(columns: [lht_triangles_contours_select_column!], distinct: Boolean): Int!
    max: lht_triangles_contours_max_fields
    min: lht_triangles_contours_min_fields
}

"aggregate max on columns"
type lht_triangles_contours_max_fields {
    uuid: uuid
}

"aggregate min on columns"
type lht_triangles_contours_min_fields {
    uuid: uuid
}

"response of any mutation on the table \"lht_triangles.contours\""
type lht_triangles_contours_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_contours!]!
}

"columns and relationships of \"lht_triangles.floors\""
type lht_triangles_floors {
    comment: String
    "An array relationship"
    entities(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "An aggregate relationship"
    entities_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    value: String!
}

"aggregated selection of \"lht_triangles.floors\""
type lht_triangles_floors_aggregate {
    aggregate: lht_triangles_floors_aggregate_fields
    nodes: [lht_triangles_floors!]!
}

"aggregate fields of \"lht_triangles.floors\""
type lht_triangles_floors_aggregate_fields {
    count(columns: [lht_triangles_floors_select_column!], distinct: Boolean): Int!
    max: lht_triangles_floors_max_fields
    min: lht_triangles_floors_min_fields
}

"aggregate max on columns"
type lht_triangles_floors_max_fields {
    comment: String
    value: String
}

"aggregate min on columns"
type lht_triangles_floors_min_fields {
    comment: String
    value: String
}

"response of any mutation on the table \"lht_triangles.floors\""
type lht_triangles_floors_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [lht_triangles_floors!]!
}

"mutation root"
type mutation_root {
    "delete data from the table: \"_enumtable.role\""
    delete__enumtable_role(
        "filter the rows which have to be deleted"
        where: _enumtable_role_bool_exp!
    ): _enumtable_role_mutation_response
    "delete single row from the table: \"_enumtable.role\""
    delete__enumtable_role_by_pk(value: String!): _enumtable_role
    "delete data from the table: \"_enumtable.users\""
    delete__enumtable_users(
        "filter the rows which have to be deleted"
        where: _enumtable_users_bool_exp!
    ): _enumtable_users_mutation_response
    "delete single row from the table: \"_enumtable.users\""
    delete__enumtable_users_by_pk(id: Int!): _enumtable_users
    "delete data from the table: \"buffgeom.objects\""
    delete_buffgeom_objects(
        "filter the rows which have to be deleted"
        where: buffgeom_objects_bool_exp!
    ): buffgeom_objects_mutation_response
    "delete single row from the table: \"buffgeom.objects\""
    delete_buffgeom_objects_by_pk(uuid: uuid!): buffgeom_objects
    "delete data from the table: \"buffgeom.attributes\""
    delete_geometry_attributes(
        "filter the rows which have to be deleted"
        where: geometry_attributes_bool_exp!
    ): geometry_attributes_mutation_response
    "delete single row from the table: \"buffgeom.attributes\""
    delete_geometry_attributes_by_pk(uuid: uuid!): geometry_attributes
    "delete data from the table: \"lht_ceiling.properties\""
    delete_lc_properties(
        "filter the rows which have to be deleted"
        where: lc_properties_bool_exp!
    ): lc_properties_mutation_response
    "delete single row from the table: \"lht_ceiling.properties\""
    delete_lc_properties_by_pk(id: Int!, subtype: String!, type: String!, uuid: uuid!): lc_properties
    "delete data from the table: \"lht_ceiling.panels\""
    delete_lht_ceiling_panels(
        "filter the rows which have to be deleted"
        where: lht_ceiling_panels_bool_exp!
    ): lht_ceiling_panels_mutation_response
    "delete single row from the table: \"lht_ceiling.panels\""
    delete_lht_ceiling_panels_by_pk(floor: String!, x: numeric!, y: numeric!): lht_ceiling_panels
    "delete data from the table: \"lht_ceiling.type_marks\""
    delete_lht_ceiling_type_marks(
        "filter the rows which have to be deleted"
        where: lht_ceiling_type_marks_bool_exp!
    ): lht_ceiling_type_marks_mutation_response
    "delete single row from the table: \"lht_ceiling.type_marks\""
    delete_lht_ceiling_type_marks_by_pk(x: numeric!, y: numeric!): lht_ceiling_type_marks
    "delete data from the table: \"lht_triangles.connectors\""
    delete_lht_triangles_connectors(
        "filter the rows which have to be deleted"
        where: lht_triangles_connectors_bool_exp!
    ): lht_triangles_connectors_mutation_response
    "delete single row from the table: \"lht_triangles.connectors\""
    delete_lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "delete data from the table: \"lht_triangles.contours\""
    delete_lht_triangles_contours(
        "filter the rows which have to be deleted"
        where: lht_triangles_contours_bool_exp!
    ): lht_triangles_contours_mutation_response
    "delete single row from the table: \"lht_triangles.contours\""
    delete_lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "delete data from the table: \"lht_triangles.floors\""
    delete_lht_triangles_floors(
        "filter the rows which have to be deleted"
        where: lht_triangles_floors_bool_exp!
    ): lht_triangles_floors_mutation_response
    "delete single row from the table: \"lht_triangles.floors\""
    delete_lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "delete data from the table: \"objects_hub\""
    delete_objects_hub(
        "filter the rows which have to be deleted"
        where: objects_hub_bool_exp!
    ): objects_hub_mutation_response
    "delete single row from the table: \"objects_hub\""
    delete_objects_hub_by_pk(uuid: uuid!): objects_hub
    "delete data from the table: \"presets.colors\""
    delete_presets_colors(
        "filter the rows which have to be deleted"
        where: presets_colors_bool_exp!
    ): presets_colors_mutation_response
    "delete single row from the table: \"presets.colors\""
    delete_presets_colors_by_pk(id: Int!, palette: Int!): presets_colors
    "delete data from the table: \"projects.infographics_hub\""
    delete_projects_infographics_hub(
        "filter the rows which have to be deleted"
        where: projects_infographics_hub_bool_exp!
    ): projects_infographics_hub_mutation_response
    "delete single row from the table: \"projects.infographics_hub\""
    delete_projects_infographics_hub_by_pk(id: uuid!): projects_infographics_hub
    "delete data from the table: \"projects.projects_hub\""
    delete_projects_projects_hub(
        "filter the rows which have to be deleted"
        where: projects_projects_hub_bool_exp!
    ): projects_projects_hub_mutation_response
    "delete single row from the table: \"projects.projects_hub\""
    delete_projects_projects_hub_by_pk(id: uuid!): projects_projects_hub
    "delete data from the table: \"projects.queries_hub\""
    delete_projects_queries_hub(
        "filter the rows which have to be deleted"
        where: projects_queries_hub_bool_exp!
    ): projects_queries_hub_mutation_response
    "delete single row from the table: \"projects.queries_hub\""
    delete_projects_queries_hub_by_pk(id: uuid!): projects_queries_hub
    "delete data from the table: \"tests.properties\""
    delete_properties(
        "filter the rows which have to be deleted"
        where: properties_bool_exp!
    ): properties_mutation_response
    "delete single row from the table: \"tests.properties\""
    delete_properties_by_pk(index: Int!, uuid: uuid!): properties
    "delete data from the table: \"threejs.types\""
    delete_threejs_types(
        "filter the rows which have to be deleted"
        where: threejs_types_bool_exp!
    ): threejs_types_mutation_response
    "delete single row from the table: \"threejs.types\""
    delete_threejs_types_by_pk(value: String!): threejs_types
    "insert data into the table: \"_enumtable.role\""
    insert__enumtable_role(
        "the rows to be inserted"
        objects: [_enumtable_role_insert_input!]!,
        "upsert condition"
        on_conflict: _enumtable_role_on_conflict
    ): _enumtable_role_mutation_response
    "insert a single row into the table: \"_enumtable.role\""
    insert__enumtable_role_one(
        "the row to be inserted"
        object: _enumtable_role_insert_input!,
        "upsert condition"
        on_conflict: _enumtable_role_on_conflict
    ): _enumtable_role
    "insert data into the table: \"_enumtable.users\""
    insert__enumtable_users(
        "the rows to be inserted"
        objects: [_enumtable_users_insert_input!]!,
        "upsert condition"
        on_conflict: _enumtable_users_on_conflict
    ): _enumtable_users_mutation_response
    "insert a single row into the table: \"_enumtable.users\""
    insert__enumtable_users_one(
        "the row to be inserted"
        object: _enumtable_users_insert_input!,
        "upsert condition"
        on_conflict: _enumtable_users_on_conflict
    ): _enumtable_users
    "insert data into the table: \"buffgeom.objects\""
    insert_buffgeom_objects(
        "the rows to be inserted"
        objects: [buffgeom_objects_insert_input!]!,
        "upsert condition"
        on_conflict: buffgeom_objects_on_conflict
    ): buffgeom_objects_mutation_response
    "insert a single row into the table: \"buffgeom.objects\""
    insert_buffgeom_objects_one(
        "the row to be inserted"
        object: buffgeom_objects_insert_input!,
        "upsert condition"
        on_conflict: buffgeom_objects_on_conflict
    ): buffgeom_objects
    "insert data into the table: \"buffgeom.attributes\""
    insert_geometry_attributes(
        "the rows to be inserted"
        objects: [geometry_attributes_insert_input!]!,
        "upsert condition"
        on_conflict: geometry_attributes_on_conflict
    ): geometry_attributes_mutation_response
    "insert a single row into the table: \"buffgeom.attributes\""
    insert_geometry_attributes_one(
        "the row to be inserted"
        object: geometry_attributes_insert_input!,
        "upsert condition"
        on_conflict: geometry_attributes_on_conflict
    ): geometry_attributes
    "insert data into the table: \"lht_ceiling.properties\""
    insert_lc_properties(
        "the rows to be inserted"
        objects: [lc_properties_insert_input!]!,
        "upsert condition"
        on_conflict: lc_properties_on_conflict
    ): lc_properties_mutation_response
    "insert a single row into the table: \"lht_ceiling.properties\""
    insert_lc_properties_one(
        "the row to be inserted"
        object: lc_properties_insert_input!,
        "upsert condition"
        on_conflict: lc_properties_on_conflict
    ): lc_properties
    "insert data into the table: \"lht_ceiling.panels\""
    insert_lht_ceiling_panels(
        "the rows to be inserted"
        objects: [lht_ceiling_panels_insert_input!]!,
        "upsert condition"
        on_conflict: lht_ceiling_panels_on_conflict
    ): lht_ceiling_panels_mutation_response
    "insert a single row into the table: \"lht_ceiling.panels\""
    insert_lht_ceiling_panels_one(
        "the row to be inserted"
        object: lht_ceiling_panels_insert_input!,
        "upsert condition"
        on_conflict: lht_ceiling_panels_on_conflict
    ): lht_ceiling_panels
    "insert data into the table: \"lht_ceiling.type_marks\""
    insert_lht_ceiling_type_marks(
        "the rows to be inserted"
        objects: [lht_ceiling_type_marks_insert_input!]!,
        "upsert condition"
        on_conflict: lht_ceiling_type_marks_on_conflict
    ): lht_ceiling_type_marks_mutation_response
    "insert a single row into the table: \"lht_ceiling.type_marks\""
    insert_lht_ceiling_type_marks_one(
        "the row to be inserted"
        object: lht_ceiling_type_marks_insert_input!,
        "upsert condition"
        on_conflict: lht_ceiling_type_marks_on_conflict
    ): lht_ceiling_type_marks
    "insert data into the table: \"lht_triangles.connectors\""
    insert_lht_triangles_connectors(
        "the rows to be inserted"
        objects: [lht_triangles_connectors_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_connectors_on_conflict
    ): lht_triangles_connectors_mutation_response
    "insert a single row into the table: \"lht_triangles.connectors\""
    insert_lht_triangles_connectors_one(
        "the row to be inserted"
        object: lht_triangles_connectors_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_connectors_on_conflict
    ): lht_triangles_connectors
    "insert data into the table: \"lht_triangles.contours\""
    insert_lht_triangles_contours(
        "the rows to be inserted"
        objects: [lht_triangles_contours_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_contours_on_conflict
    ): lht_triangles_contours_mutation_response
    "insert a single row into the table: \"lht_triangles.contours\""
    insert_lht_triangles_contours_one(
        "the row to be inserted"
        object: lht_triangles_contours_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_contours_on_conflict
    ): lht_triangles_contours
    "insert data into the table: \"lht_triangles.floors\""
    insert_lht_triangles_floors(
        "the rows to be inserted"
        objects: [lht_triangles_floors_insert_input!]!,
        "upsert condition"
        on_conflict: lht_triangles_floors_on_conflict
    ): lht_triangles_floors_mutation_response
    "insert a single row into the table: \"lht_triangles.floors\""
    insert_lht_triangles_floors_one(
        "the row to be inserted"
        object: lht_triangles_floors_insert_input!,
        "upsert condition"
        on_conflict: lht_triangles_floors_on_conflict
    ): lht_triangles_floors
    "insert data into the table: \"objects_hub\""
    insert_objects_hub(
        "the rows to be inserted"
        objects: [objects_hub_insert_input!]!,
        "upsert condition"
        on_conflict: objects_hub_on_conflict
    ): objects_hub_mutation_response
    "insert a single row into the table: \"objects_hub\""
    insert_objects_hub_one(
        "the row to be inserted"
        object: objects_hub_insert_input!,
        "upsert condition"
        on_conflict: objects_hub_on_conflict
    ): objects_hub
    "insert data into the table: \"presets.colors\""
    insert_presets_colors(
        "the rows to be inserted"
        objects: [presets_colors_insert_input!]!,
        "upsert condition"
        on_conflict: presets_colors_on_conflict
    ): presets_colors_mutation_response
    "insert a single row into the table: \"presets.colors\""
    insert_presets_colors_one(
        "the row to be inserted"
        object: presets_colors_insert_input!,
        "upsert condition"
        on_conflict: presets_colors_on_conflict
    ): presets_colors
    "insert data into the table: \"projects.infographics_hub\""
    insert_projects_infographics_hub(
        "the rows to be inserted"
        objects: [projects_infographics_hub_insert_input!]!,
        "upsert condition"
        on_conflict: projects_infographics_hub_on_conflict
    ): projects_infographics_hub_mutation_response
    "insert a single row into the table: \"projects.infographics_hub\""
    insert_projects_infographics_hub_one(
        "the row to be inserted"
        object: projects_infographics_hub_insert_input!,
        "upsert condition"
        on_conflict: projects_infographics_hub_on_conflict
    ): projects_infographics_hub
    "insert data into the table: \"projects.projects_hub\""
    insert_projects_projects_hub(
        "the rows to be inserted"
        objects: [projects_projects_hub_insert_input!]!,
        "upsert condition"
        on_conflict: projects_projects_hub_on_conflict
    ): projects_projects_hub_mutation_response
    "insert a single row into the table: \"projects.projects_hub\""
    insert_projects_projects_hub_one(
        "the row to be inserted"
        object: projects_projects_hub_insert_input!,
        "upsert condition"
        on_conflict: projects_projects_hub_on_conflict
    ): projects_projects_hub
    "insert data into the table: \"projects.queries_hub\""
    insert_projects_queries_hub(
        "the rows to be inserted"
        objects: [projects_queries_hub_insert_input!]!,
        "upsert condition"
        on_conflict: projects_queries_hub_on_conflict
    ): projects_queries_hub_mutation_response
    "insert a single row into the table: \"projects.queries_hub\""
    insert_projects_queries_hub_one(
        "the row to be inserted"
        object: projects_queries_hub_insert_input!,
        "upsert condition"
        on_conflict: projects_queries_hub_on_conflict
    ): projects_queries_hub
    "insert data into the table: \"tests.properties\""
    insert_properties(
        "the rows to be inserted"
        objects: [properties_insert_input!]!,
        "upsert condition"
        on_conflict: properties_on_conflict
    ): properties_mutation_response
    "insert a single row into the table: \"tests.properties\""
    insert_properties_one(
        "the row to be inserted"
        object: properties_insert_input!,
        "upsert condition"
        on_conflict: properties_on_conflict
    ): properties
    "insert data into the table: \"threejs.types\""
    insert_threejs_types(
        "the rows to be inserted"
        objects: [threejs_types_insert_input!]!,
        "upsert condition"
        on_conflict: threejs_types_on_conflict
    ): threejs_types_mutation_response
    "insert a single row into the table: \"threejs.types\""
    insert_threejs_types_one(
        "the row to be inserted"
        object: threejs_types_insert_input!,
        "upsert condition"
        on_conflict: threejs_types_on_conflict
    ): threejs_types
    "update data of the table: \"_enumtable.role\""
    update__enumtable_role(
        "sets the columns of the filtered rows to the given values"
        _set: _enumtable_role_set_input,
        "filter the rows which have to be updated"
        where: _enumtable_role_bool_exp!
    ): _enumtable_role_mutation_response
    "update single row of the table: \"_enumtable.role\""
    update__enumtable_role_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: _enumtable_role_set_input,
        pk_columns: _enumtable_role_pk_columns_input!
    ): _enumtable_role
    "update multiples rows of table: \"_enumtable.role\""
    update__enumtable_role_many(
        "updates to execute, in order"
        updates: [_enumtable_role_updates!]!
    ): [_enumtable_role_mutation_response]
    "update data of the table: \"_enumtable.users\""
    update__enumtable_users(
        "increments the numeric columns with given value of the filtered values"
        _inc: _enumtable_users_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: _enumtable_users_set_input,
        "filter the rows which have to be updated"
        where: _enumtable_users_bool_exp!
    ): _enumtable_users_mutation_response
    "update single row of the table: \"_enumtable.users\""
    update__enumtable_users_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: _enumtable_users_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: _enumtable_users_set_input,
        pk_columns: _enumtable_users_pk_columns_input!
    ): _enumtable_users
    "update multiples rows of table: \"_enumtable.users\""
    update__enumtable_users_many(
        "updates to execute, in order"
        updates: [_enumtable_users_updates!]!
    ): [_enumtable_users_mutation_response]
    "update data of the table: \"buffgeom.objects\""
    update_buffgeom_objects(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: buffgeom_objects_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: buffgeom_objects_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: buffgeom_objects_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: buffgeom_objects_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: buffgeom_objects_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: buffgeom_objects_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: buffgeom_objects_set_input,
        "filter the rows which have to be updated"
        where: buffgeom_objects_bool_exp!
    ): buffgeom_objects_mutation_response
    "update single row of the table: \"buffgeom.objects\""
    update_buffgeom_objects_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: buffgeom_objects_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: buffgeom_objects_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: buffgeom_objects_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: buffgeom_objects_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: buffgeom_objects_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: buffgeom_objects_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: buffgeom_objects_set_input,
        pk_columns: buffgeom_objects_pk_columns_input!
    ): buffgeom_objects
    "update multiples rows of table: \"buffgeom.objects\""
    update_buffgeom_objects_many(
        "updates to execute, in order"
        updates: [buffgeom_objects_updates!]!
    ): [buffgeom_objects_mutation_response]
    "update data of the table: \"buffgeom.attributes\""
    update_geometry_attributes(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: geometry_attributes_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: geometry_attributes_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: geometry_attributes_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: geometry_attributes_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: geometry_attributes_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: geometry_attributes_set_input,
        "filter the rows which have to be updated"
        where: geometry_attributes_bool_exp!
    ): geometry_attributes_mutation_response
    "update single row of the table: \"buffgeom.attributes\""
    update_geometry_attributes_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: geometry_attributes_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: geometry_attributes_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: geometry_attributes_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: geometry_attributes_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: geometry_attributes_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: geometry_attributes_set_input,
        pk_columns: geometry_attributes_pk_columns_input!
    ): geometry_attributes
    "update multiples rows of table: \"buffgeom.attributes\""
    update_geometry_attributes_many(
        "updates to execute, in order"
        updates: [geometry_attributes_updates!]!
    ): [geometry_attributes_mutation_response]
    "update data of the table: \"lht_ceiling.properties\""
    update_lc_properties(
        "increments the numeric columns with given value of the filtered values"
        _inc: lc_properties_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lc_properties_set_input,
        "filter the rows which have to be updated"
        where: lc_properties_bool_exp!
    ): lc_properties_mutation_response
    "update single row of the table: \"lht_ceiling.properties\""
    update_lc_properties_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: lc_properties_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lc_properties_set_input,
        pk_columns: lc_properties_pk_columns_input!
    ): lc_properties
    "update multiples rows of table: \"lht_ceiling.properties\""
    update_lc_properties_many(
        "updates to execute, in order"
        updates: [lc_properties_updates!]!
    ): [lc_properties_mutation_response]
    "update data of the table: \"lht_ceiling.panels\""
    update_lht_ceiling_panels(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_ceiling_panels_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_ceiling_panels_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_ceiling_panels_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_ceiling_panels_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_ceiling_panels_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_ceiling_panels_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_ceiling_panels_set_input,
        "filter the rows which have to be updated"
        where: lht_ceiling_panels_bool_exp!
    ): lht_ceiling_panels_mutation_response
    "update single row of the table: \"lht_ceiling.panels\""
    update_lht_ceiling_panels_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_ceiling_panels_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_ceiling_panels_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_ceiling_panels_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_ceiling_panels_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_ceiling_panels_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_ceiling_panels_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_ceiling_panels_set_input,
        pk_columns: lht_ceiling_panels_pk_columns_input!
    ): lht_ceiling_panels
    "update multiples rows of table: \"lht_ceiling.panels\""
    update_lht_ceiling_panels_many(
        "updates to execute, in order"
        updates: [lht_ceiling_panels_updates!]!
    ): [lht_ceiling_panels_mutation_response]
    "update data of the table: \"lht_ceiling.type_marks\""
    update_lht_ceiling_type_marks(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_ceiling_type_marks_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_ceiling_type_marks_set_input,
        "filter the rows which have to be updated"
        where: lht_ceiling_type_marks_bool_exp!
    ): lht_ceiling_type_marks_mutation_response
    "update single row of the table: \"lht_ceiling.type_marks\""
    update_lht_ceiling_type_marks_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_ceiling_type_marks_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_ceiling_type_marks_set_input,
        pk_columns: lht_ceiling_type_marks_pk_columns_input!
    ): lht_ceiling_type_marks
    "update multiples rows of table: \"lht_ceiling.type_marks\""
    update_lht_ceiling_type_marks_many(
        "updates to execute, in order"
        updates: [lht_ceiling_type_marks_updates!]!
    ): [lht_ceiling_type_marks_mutation_response]
    "update data of the table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_triangles_connectors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_connectors_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_connectors_bool_exp!
    ): lht_triangles_connectors_mutation_response
    "update single row of the table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: lht_triangles_connectors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_connectors_set_input,
        pk_columns: lht_triangles_connectors_pk_columns_input!
    ): lht_triangles_connectors
    "update multiples rows of table: \"lht_triangles.connectors\""
    update_lht_triangles_connectors_many(
        "updates to execute, in order"
        updates: [lht_triangles_connectors_updates!]!
    ): [lht_triangles_connectors_mutation_response]
    "update data of the table: \"lht_triangles.contours\""
    update_lht_triangles_contours(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_contours_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_contours_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_contours_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_contours_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_contours_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_contours_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_contours_bool_exp!
    ): lht_triangles_contours_mutation_response
    "update single row of the table: \"lht_triangles.contours\""
    update_lht_triangles_contours_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: lht_triangles_contours_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: lht_triangles_contours_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: lht_triangles_contours_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: lht_triangles_contours_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: lht_triangles_contours_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_contours_set_input,
        pk_columns: lht_triangles_contours_pk_columns_input!
    ): lht_triangles_contours
    "update multiples rows of table: \"lht_triangles.contours\""
    update_lht_triangles_contours_many(
        "updates to execute, in order"
        updates: [lht_triangles_contours_updates!]!
    ): [lht_triangles_contours_mutation_response]
    "update data of the table: \"lht_triangles.floors\""
    update_lht_triangles_floors(
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_floors_set_input,
        "filter the rows which have to be updated"
        where: lht_triangles_floors_bool_exp!
    ): lht_triangles_floors_mutation_response
    "update single row of the table: \"lht_triangles.floors\""
    update_lht_triangles_floors_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: lht_triangles_floors_set_input,
        pk_columns: lht_triangles_floors_pk_columns_input!
    ): lht_triangles_floors
    "update multiples rows of table: \"lht_triangles.floors\""
    update_lht_triangles_floors_many(
        "updates to execute, in order"
        updates: [lht_triangles_floors_updates!]!
    ): [lht_triangles_floors_mutation_response]
    "update data of the table: \"objects_hub\""
    update_objects_hub(
        "sets the columns of the filtered rows to the given values"
        _set: objects_hub_set_input,
        "filter the rows which have to be updated"
        where: objects_hub_bool_exp!
    ): objects_hub_mutation_response
    "update single row of the table: \"objects_hub\""
    update_objects_hub_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: objects_hub_set_input,
        pk_columns: objects_hub_pk_columns_input!
    ): objects_hub
    "update multiples rows of table: \"objects_hub\""
    update_objects_hub_many(
        "updates to execute, in order"
        updates: [objects_hub_updates!]!
    ): [objects_hub_mutation_response]
    "update data of the table: \"presets.colors\""
    update_presets_colors(
        "increments the numeric columns with given value of the filtered values"
        _inc: presets_colors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: presets_colors_set_input,
        "filter the rows which have to be updated"
        where: presets_colors_bool_exp!
    ): presets_colors_mutation_response
    "update single row of the table: \"presets.colors\""
    update_presets_colors_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: presets_colors_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: presets_colors_set_input,
        pk_columns: presets_colors_pk_columns_input!
    ): presets_colors
    "update multiples rows of table: \"presets.colors\""
    update_presets_colors_many(
        "updates to execute, in order"
        updates: [presets_colors_updates!]!
    ): [presets_colors_mutation_response]
    "update data of the table: \"projects.infographics_hub\""
    update_projects_infographics_hub(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: projects_infographics_hub_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: projects_infographics_hub_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: projects_infographics_hub_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: projects_infographics_hub_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: projects_infographics_hub_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: projects_infographics_hub_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: projects_infographics_hub_set_input,
        "filter the rows which have to be updated"
        where: projects_infographics_hub_bool_exp!
    ): projects_infographics_hub_mutation_response
    "update single row of the table: \"projects.infographics_hub\""
    update_projects_infographics_hub_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: projects_infographics_hub_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: projects_infographics_hub_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: projects_infographics_hub_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: projects_infographics_hub_delete_key_input,
        "increments the numeric columns with given value of the filtered values"
        _inc: projects_infographics_hub_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: projects_infographics_hub_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: projects_infographics_hub_set_input,
        pk_columns: projects_infographics_hub_pk_columns_input!
    ): projects_infographics_hub
    "update multiples rows of table: \"projects.infographics_hub\""
    update_projects_infographics_hub_many(
        "updates to execute, in order"
        updates: [projects_infographics_hub_updates!]!
    ): [projects_infographics_hub_mutation_response]
    "update data of the table: \"projects.projects_hub\""
    update_projects_projects_hub(
        "sets the columns of the filtered rows to the given values"
        _set: projects_projects_hub_set_input,
        "filter the rows which have to be updated"
        where: projects_projects_hub_bool_exp!
    ): projects_projects_hub_mutation_response
    "update single row of the table: \"projects.projects_hub\""
    update_projects_projects_hub_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: projects_projects_hub_set_input,
        pk_columns: projects_projects_hub_pk_columns_input!
    ): projects_projects_hub
    "update multiples rows of table: \"projects.projects_hub\""
    update_projects_projects_hub_many(
        "updates to execute, in order"
        updates: [projects_projects_hub_updates!]!
    ): [projects_projects_hub_mutation_response]
    "update data of the table: \"projects.queries_hub\""
    update_projects_queries_hub(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: projects_queries_hub_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: projects_queries_hub_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: projects_queries_hub_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: projects_queries_hub_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: projects_queries_hub_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: projects_queries_hub_set_input,
        "filter the rows which have to be updated"
        where: projects_queries_hub_bool_exp!
    ): projects_queries_hub_mutation_response
    "update single row of the table: \"projects.queries_hub\""
    update_projects_queries_hub_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: projects_queries_hub_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: projects_queries_hub_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: projects_queries_hub_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: projects_queries_hub_delete_key_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: projects_queries_hub_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: projects_queries_hub_set_input,
        pk_columns: projects_queries_hub_pk_columns_input!
    ): projects_queries_hub
    "update multiples rows of table: \"projects.queries_hub\""
    update_projects_queries_hub_many(
        "updates to execute, in order"
        updates: [projects_queries_hub_updates!]!
    ): [projects_queries_hub_mutation_response]
    "update data of the table: \"tests.properties\""
    update_properties(
        "increments the numeric columns with given value of the filtered values"
        _inc: properties_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: properties_set_input,
        "filter the rows which have to be updated"
        where: properties_bool_exp!
    ): properties_mutation_response
    "update single row of the table: \"tests.properties\""
    update_properties_by_pk(
        "increments the numeric columns with given value of the filtered values"
        _inc: properties_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: properties_set_input,
        pk_columns: properties_pk_columns_input!
    ): properties
    "update multiples rows of table: \"tests.properties\""
    update_properties_many(
        "updates to execute, in order"
        updates: [properties_updates!]!
    ): [properties_mutation_response]
    "update data of the table: \"threejs.types\""
    update_threejs_types(
        "sets the columns of the filtered rows to the given values"
        _set: threejs_types_set_input,
        "filter the rows which have to be updated"
        where: threejs_types_bool_exp!
    ): threejs_types_mutation_response
    "update single row of the table: \"threejs.types\""
    update_threejs_types_by_pk(
        "sets the columns of the filtered rows to the given values"
        _set: threejs_types_set_input,
        pk_columns: threejs_types_pk_columns_input!
    ): threejs_types
    "update multiples rows of table: \"threejs.types\""
    update_threejs_types_many(
        "updates to execute, in order"
        updates: [threejs_types_updates!]!
    ): [threejs_types_mutation_response]
}

"columns and relationships of \"objects_hub\""
type objects_hub {
    children: oidvector
    name: String
    type: String
    "An object relationship"
    type_relay: threejs_types
    uuid: uuid!
}

"aggregated selection of \"objects_hub\""
type objects_hub_aggregate {
    aggregate: objects_hub_aggregate_fields
    nodes: [objects_hub!]!
}

"aggregate fields of \"objects_hub\""
type objects_hub_aggregate_fields {
    count(columns: [objects_hub_select_column!], distinct: Boolean): Int!
    max: objects_hub_max_fields
    min: objects_hub_min_fields
}

"aggregate max on columns"
type objects_hub_max_fields {
    name: String
    type: String
    uuid: uuid
}

"aggregate min on columns"
type objects_hub_min_fields {
    name: String
    type: String
    uuid: uuid
}

"response of any mutation on the table \"objects_hub\""
type objects_hub_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [objects_hub!]!
}

"colours using in scene"
type presets_colors {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int!
    name: name
    palette: Int!
    r: Int
}

"aggregated selection of \"presets.colors\""
type presets_colors_aggregate {
    aggregate: presets_colors_aggregate_fields
    nodes: [presets_colors!]!
}

"aggregate fields of \"presets.colors\""
type presets_colors_aggregate_fields {
    avg: presets_colors_avg_fields
    count(columns: [presets_colors_select_column!], distinct: Boolean): Int!
    max: presets_colors_max_fields
    min: presets_colors_min_fields
    stddev: presets_colors_stddev_fields
    stddev_pop: presets_colors_stddev_pop_fields
    stddev_samp: presets_colors_stddev_samp_fields
    sum: presets_colors_sum_fields
    var_pop: presets_colors_var_pop_fields
    var_samp: presets_colors_var_samp_fields
    variance: presets_colors_variance_fields
}

"aggregate avg on columns"
type presets_colors_avg_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate max on columns"
type presets_colors_max_fields {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int
    palette: Int
    r: Int
}

"aggregate min on columns"
type presets_colors_min_fields {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int
    palette: Int
    r: Int
}

"response of any mutation on the table \"presets.colors\""
type presets_colors_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [presets_colors!]!
}

"aggregate stddev on columns"
type presets_colors_stddev_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate stddev_pop on columns"
type presets_colors_stddev_pop_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate stddev_samp on columns"
type presets_colors_stddev_samp_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate sum on columns"
type presets_colors_sum_fields {
    b: Int
    decimal: Int
    g: Int
    id: Int
    palette: Int
    r: Int
}

"aggregate var_pop on columns"
type presets_colors_var_pop_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate var_samp on columns"
type presets_colors_var_samp_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"aggregate variance on columns"
type presets_colors_variance_fields {
    b: Float
    decimal: Float
    g: Float
    id: Float
    palette: Float
    r: Float
}

"columns and relationships of \"projects.infographics_hub\""
type projects_infographics_hub {
    body(
        "JSON select path"
        path: String
    ): jsonb!
    cr: timestamptz!
    id: uuid!
    name: String!
    object_id: Int!
    project_name: String
}

"aggregated selection of \"projects.infographics_hub\""
type projects_infographics_hub_aggregate {
    aggregate: projects_infographics_hub_aggregate_fields
    nodes: [projects_infographics_hub!]!
}

"aggregate fields of \"projects.infographics_hub\""
type projects_infographics_hub_aggregate_fields {
    avg: projects_infographics_hub_avg_fields
    count(columns: [projects_infographics_hub_select_column!], distinct: Boolean): Int!
    max: projects_infographics_hub_max_fields
    min: projects_infographics_hub_min_fields
    stddev: projects_infographics_hub_stddev_fields
    stddev_pop: projects_infographics_hub_stddev_pop_fields
    stddev_samp: projects_infographics_hub_stddev_samp_fields
    sum: projects_infographics_hub_sum_fields
    var_pop: projects_infographics_hub_var_pop_fields
    var_samp: projects_infographics_hub_var_samp_fields
    variance: projects_infographics_hub_variance_fields
}

"aggregate avg on columns"
type projects_infographics_hub_avg_fields {
    object_id: Float
}

"aggregate max on columns"
type projects_infographics_hub_max_fields {
    cr: timestamptz
    id: uuid
    name: String
    object_id: Int
    project_name: String
}

"aggregate min on columns"
type projects_infographics_hub_min_fields {
    cr: timestamptz
    id: uuid
    name: String
    object_id: Int
    project_name: String
}

"response of any mutation on the table \"projects.infographics_hub\""
type projects_infographics_hub_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [projects_infographics_hub!]!
}

"aggregate stddev on columns"
type projects_infographics_hub_stddev_fields {
    object_id: Float
}

"aggregate stddev_pop on columns"
type projects_infographics_hub_stddev_pop_fields {
    object_id: Float
}

"aggregate stddev_samp on columns"
type projects_infographics_hub_stddev_samp_fields {
    object_id: Float
}

"aggregate sum on columns"
type projects_infographics_hub_sum_fields {
    object_id: Int
}

"aggregate var_pop on columns"
type projects_infographics_hub_var_pop_fields {
    object_id: Float
}

"aggregate var_samp on columns"
type projects_infographics_hub_var_samp_fields {
    object_id: Float
}

"aggregate variance on columns"
type projects_infographics_hub_variance_fields {
    object_id: Float
}

"columns and relationships of \"projects.projects_hub\""
type projects_projects_hub {
    id: uuid!
    last_visited: timestamptz
    name: String
    thumb: String
}

"aggregated selection of \"projects.projects_hub\""
type projects_projects_hub_aggregate {
    aggregate: projects_projects_hub_aggregate_fields
    nodes: [projects_projects_hub!]!
}

"aggregate fields of \"projects.projects_hub\""
type projects_projects_hub_aggregate_fields {
    count(columns: [projects_projects_hub_select_column!], distinct: Boolean): Int!
    max: projects_projects_hub_max_fields
    min: projects_projects_hub_min_fields
}

"aggregate max on columns"
type projects_projects_hub_max_fields {
    id: uuid
    last_visited: timestamptz
    name: String
    thumb: String
}

"aggregate min on columns"
type projects_projects_hub_min_fields {
    id: uuid
    last_visited: timestamptz
    name: String
    thumb: String
}

"response of any mutation on the table \"projects.projects_hub\""
type projects_projects_hub_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [projects_projects_hub!]!
}

"columns and relationships of \"projects.queries_hub\""
type projects_queries_hub {
    body(
        "JSON select path"
        path: String
    ): jsonb!
    cr: timestamptz
    endpoint: String!
    id: uuid!
    name: String!
    project_name: String
    tags(
        "JSON select path"
        path: String
    ): jsonb!
}

"aggregated selection of \"projects.queries_hub\""
type projects_queries_hub_aggregate {
    aggregate: projects_queries_hub_aggregate_fields
    nodes: [projects_queries_hub!]!
}

"aggregate fields of \"projects.queries_hub\""
type projects_queries_hub_aggregate_fields {
    count(columns: [projects_queries_hub_select_column!], distinct: Boolean): Int!
    max: projects_queries_hub_max_fields
    min: projects_queries_hub_min_fields
}

"aggregate max on columns"
type projects_queries_hub_max_fields {
    cr: timestamptz
    endpoint: String
    id: uuid
    name: String
    project_name: String
}

"aggregate min on columns"
type projects_queries_hub_min_fields {
    cr: timestamptz
    endpoint: String
    id: uuid
    name: String
    project_name: String
}

"response of any mutation on the table \"projects.queries_hub\""
type projects_queries_hub_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [projects_queries_hub!]!
}

"columns and relationships of \"tests.properties\""
type properties {
    area: numeric!
    index: Int!
    part: String
    stage: String
    status: String
    subtype: Int!
    type: String!
    uuid: uuid!
}

"aggregated selection of \"tests.properties\""
type properties_aggregate {
    aggregate: properties_aggregate_fields
    nodes: [properties!]!
}

"aggregate fields of \"tests.properties\""
type properties_aggregate_fields {
    avg: properties_avg_fields
    count(columns: [properties_select_column!], distinct: Boolean): Int!
    max: properties_max_fields
    min: properties_min_fields
    stddev: properties_stddev_fields
    stddev_pop: properties_stddev_pop_fields
    stddev_samp: properties_stddev_samp_fields
    sum: properties_sum_fields
    var_pop: properties_var_pop_fields
    var_samp: properties_var_samp_fields
    variance: properties_variance_fields
}

"aggregate avg on columns"
type properties_avg_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate max on columns"
type properties_max_fields {
    area: numeric
    index: Int
    part: String
    stage: String
    status: String
    subtype: Int
    type: String
    uuid: uuid
}

"aggregate min on columns"
type properties_min_fields {
    area: numeric
    index: Int
    part: String
    stage: String
    status: String
    subtype: Int
    type: String
    uuid: uuid
}

"response of any mutation on the table \"tests.properties\""
type properties_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [properties!]!
}

"aggregate stddev on columns"
type properties_stddev_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate stddev_pop on columns"
type properties_stddev_pop_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate stddev_samp on columns"
type properties_stddev_samp_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate sum on columns"
type properties_sum_fields {
    area: numeric
    index: Int
    subtype: Int
}

"aggregate var_pop on columns"
type properties_var_pop_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate var_samp on columns"
type properties_var_samp_fields {
    area: Float
    index: Float
    subtype: Float
}

"aggregate variance on columns"
type properties_variance_fields {
    area: Float
    index: Float
    subtype: Float
}

type query_root {
    "query _Entity union"
    _entities(representations: [_Any!]!): _Entity
    "fetch data from the table: \"_enumtable.role\""
    _enumtable_role(
        "distinct select on columns"
        distinct_on: [_enumtable_role_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_role_order_by!],
        "filter the rows returned"
        where: _enumtable_role_bool_exp
    ): [_enumtable_role!]!
    "fetch aggregated fields from the table: \"_enumtable.role\""
    _enumtable_role_aggregate(
        "distinct select on columns"
        distinct_on: [_enumtable_role_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_role_order_by!],
        "filter the rows returned"
        where: _enumtable_role_bool_exp
    ): _enumtable_role_aggregate!
    "fetch data from the table: \"_enumtable.role\" using primary key columns"
    _enumtable_role_by_pk(value: String!): _enumtable_role
    "fetch data from the table: \"_enumtable.users\""
    _enumtable_users(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): [_enumtable_users!]!
    "fetch aggregated fields from the table: \"_enumtable.users\""
    _enumtable_users_aggregate(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): _enumtable_users_aggregate!
    "fetch data from the table: \"_enumtable.users\" using primary key columns"
    _enumtable_users_by_pk(id: Int!): _enumtable_users
    _service: _Service!
    "fetch data from the table: \"buffgeom.objects\""
    buffgeom_objects(
        "distinct select on columns"
        distinct_on: [buffgeom_objects_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [buffgeom_objects_order_by!],
        "filter the rows returned"
        where: buffgeom_objects_bool_exp
    ): [buffgeom_objects!]!
    "fetch aggregated fields from the table: \"buffgeom.objects\""
    buffgeom_objects_aggregate(
        "distinct select on columns"
        distinct_on: [buffgeom_objects_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [buffgeom_objects_order_by!],
        "filter the rows returned"
        where: buffgeom_objects_bool_exp
    ): buffgeom_objects_aggregate!
    "fetch data from the table: \"buffgeom.objects\" using primary key columns"
    buffgeom_objects_by_pk(uuid: uuid!): buffgeom_objects
    "fetch data from the table: \"buffgeom.attributes\""
    geometry_attributes(
        "distinct select on columns"
        distinct_on: [geometry_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [geometry_attributes_order_by!],
        "filter the rows returned"
        where: geometry_attributes_bool_exp
    ): [geometry_attributes!]!
    "fetch aggregated fields from the table: \"buffgeom.attributes\""
    geometry_attributes_aggregate(
        "distinct select on columns"
        distinct_on: [geometry_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [geometry_attributes_order_by!],
        "filter the rows returned"
        where: geometry_attributes_bool_exp
    ): geometry_attributes_aggregate!
    "fetch data from the table: \"buffgeom.attributes\" using primary key columns"
    geometry_attributes_by_pk(uuid: uuid!): geometry_attributes
    "fetch data from the table: \"lht_ceiling.properties\""
    lc_properties(
        "distinct select on columns"
        distinct_on: [lc_properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lc_properties_order_by!],
        "filter the rows returned"
        where: lc_properties_bool_exp
    ): [lc_properties!]!
    "fetch aggregated fields from the table: \"lht_ceiling.properties\""
    lc_properties_aggregate(
        "distinct select on columns"
        distinct_on: [lc_properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lc_properties_order_by!],
        "filter the rows returned"
        where: lc_properties_bool_exp
    ): lc_properties_aggregate!
    "fetch data from the table: \"lht_ceiling.properties\" using primary key columns"
    lc_properties_by_pk(id: Int!, subtype: String!, type: String!, uuid: uuid!): lc_properties
    "fetch data from the table: \"lht_ceiling.panels\""
    lht_ceiling_panels(
        "distinct select on columns"
        distinct_on: [lht_ceiling_panels_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_panels_order_by!],
        "filter the rows returned"
        where: lht_ceiling_panels_bool_exp
    ): [lht_ceiling_panels!]!
    "fetch aggregated fields from the table: \"lht_ceiling.panels\""
    lht_ceiling_panels_aggregate(
        "distinct select on columns"
        distinct_on: [lht_ceiling_panels_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_panels_order_by!],
        "filter the rows returned"
        where: lht_ceiling_panels_bool_exp
    ): lht_ceiling_panels_aggregate!
    "fetch data from the table: \"lht_ceiling.panels\" using primary key columns"
    lht_ceiling_panels_by_pk(floor: String!, x: numeric!, y: numeric!): lht_ceiling_panels
    "fetch data from the table: \"lht_ceiling.type_marks\""
    lht_ceiling_type_marks(
        "distinct select on columns"
        distinct_on: [lht_ceiling_type_marks_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_type_marks_order_by!],
        "filter the rows returned"
        where: lht_ceiling_type_marks_bool_exp
    ): [lht_ceiling_type_marks!]!
    "fetch aggregated fields from the table: \"lht_ceiling.type_marks\""
    lht_ceiling_type_marks_aggregate(
        "distinct select on columns"
        distinct_on: [lht_ceiling_type_marks_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_type_marks_order_by!],
        "filter the rows returned"
        where: lht_ceiling_type_marks_bool_exp
    ): lht_ceiling_type_marks_aggregate!
    "fetch data from the table: \"lht_ceiling.type_marks\" using primary key columns"
    lht_ceiling_type_marks_by_pk(x: numeric!, y: numeric!): lht_ceiling_type_marks
    "fetch data from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch aggregated fields from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): lht_triangles_connectors_aggregate!
    "fetch data from the table: \"lht_triangles.connectors\" using primary key columns"
    lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "fetch data from the table: \"lht_triangles.contours\""
    lht_triangles_contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch aggregated fields from the table: \"lht_triangles.contours\""
    lht_triangles_contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    "fetch data from the table: \"lht_triangles.contours\" using primary key columns"
    lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "fetch data from the table: \"lht_triangles.floors\""
    lht_triangles_floors(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch aggregated fields from the table: \"lht_triangles.floors\""
    lht_triangles_floors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): lht_triangles_floors_aggregate!
    "fetch data from the table: \"lht_triangles.floors\" using primary key columns"
    lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "fetch data from the table: \"objects_hub\""
    objects_hub(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch aggregated fields from the table: \"objects_hub\""
    objects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    "fetch data from the table: \"objects_hub\" using primary key columns"
    objects_hub_by_pk(uuid: uuid!): objects_hub
    "fetch data from the table: \"presets.colors\""
    presets_colors(
        "distinct select on columns"
        distinct_on: [presets_colors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [presets_colors_order_by!],
        "filter the rows returned"
        where: presets_colors_bool_exp
    ): [presets_colors!]!
    "fetch aggregated fields from the table: \"presets.colors\""
    presets_colors_aggregate(
        "distinct select on columns"
        distinct_on: [presets_colors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [presets_colors_order_by!],
        "filter the rows returned"
        where: presets_colors_bool_exp
    ): presets_colors_aggregate!
    "fetch data from the table: \"presets.colors\" using primary key columns"
    presets_colors_by_pk(id: Int!, palette: Int!): presets_colors
    "fetch data from the table: \"projects.infographics_hub\""
    projects_infographics_hub(
        "distinct select on columns"
        distinct_on: [projects_infographics_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_infographics_hub_order_by!],
        "filter the rows returned"
        where: projects_infographics_hub_bool_exp
    ): [projects_infographics_hub!]!
    "fetch aggregated fields from the table: \"projects.infographics_hub\""
    projects_infographics_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_infographics_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_infographics_hub_order_by!],
        "filter the rows returned"
        where: projects_infographics_hub_bool_exp
    ): projects_infographics_hub_aggregate!
    "fetch data from the table: \"projects.infographics_hub\" using primary key columns"
    projects_infographics_hub_by_pk(id: uuid!): projects_infographics_hub
    "fetch data from the table: \"projects.projects_hub\""
    projects_projects_hub(
        "distinct select on columns"
        distinct_on: [projects_projects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_projects_hub_order_by!],
        "filter the rows returned"
        where: projects_projects_hub_bool_exp
    ): [projects_projects_hub!]!
    "fetch aggregated fields from the table: \"projects.projects_hub\""
    projects_projects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_projects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_projects_hub_order_by!],
        "filter the rows returned"
        where: projects_projects_hub_bool_exp
    ): projects_projects_hub_aggregate!
    "fetch data from the table: \"projects.projects_hub\" using primary key columns"
    projects_projects_hub_by_pk(id: uuid!): projects_projects_hub
    "fetch data from the table: \"projects.queries_hub\""
    projects_queries_hub(
        "distinct select on columns"
        distinct_on: [projects_queries_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_queries_hub_order_by!],
        "filter the rows returned"
        where: projects_queries_hub_bool_exp
    ): [projects_queries_hub!]!
    "fetch aggregated fields from the table: \"projects.queries_hub\""
    projects_queries_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_queries_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_queries_hub_order_by!],
        "filter the rows returned"
        where: projects_queries_hub_bool_exp
    ): projects_queries_hub_aggregate!
    "fetch data from the table: \"projects.queries_hub\" using primary key columns"
    projects_queries_hub_by_pk(id: uuid!): projects_queries_hub
    "fetch data from the table: \"tests.properties\""
    properties(
        "distinct select on columns"
        distinct_on: [properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [properties_order_by!],
        "filter the rows returned"
        where: properties_bool_exp
    ): [properties!]!
    "fetch aggregated fields from the table: \"tests.properties\""
    properties_aggregate(
        "distinct select on columns"
        distinct_on: [properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [properties_order_by!],
        "filter the rows returned"
        where: properties_bool_exp
    ): properties_aggregate!
    "fetch data from the table: \"tests.properties\" using primary key columns"
    properties_by_pk(index: Int!, uuid: uuid!): properties
    "fetch data from the table: \"threejs.types\""
    threejs_types(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
    "fetch aggregated fields from the table: \"threejs.types\""
    threejs_types_aggregate(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): threejs_types_aggregate!
    "fetch data from the table: \"threejs.types\" using primary key columns"
    threejs_types_by_pk(value: String!): threejs_types
}

type subscription_root {
    "fetch data from the table: \"_enumtable.role\""
    _enumtable_role(
        "distinct select on columns"
        distinct_on: [_enumtable_role_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_role_order_by!],
        "filter the rows returned"
        where: _enumtable_role_bool_exp
    ): [_enumtable_role!]!
    "fetch aggregated fields from the table: \"_enumtable.role\""
    _enumtable_role_aggregate(
        "distinct select on columns"
        distinct_on: [_enumtable_role_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_role_order_by!],
        "filter the rows returned"
        where: _enumtable_role_bool_exp
    ): _enumtable_role_aggregate!
    "fetch data from the table: \"_enumtable.role\" using primary key columns"
    _enumtable_role_by_pk(value: String!): _enumtable_role
    "fetch data from the table in a streaming manner: \"_enumtable.role\""
    _enumtable_role_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [_enumtable_role_stream_cursor_input]!,
        "filter the rows returned"
        where: _enumtable_role_bool_exp
    ): [_enumtable_role!]!
    "fetch data from the table: \"_enumtable.users\""
    _enumtable_users(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): [_enumtable_users!]!
    "fetch aggregated fields from the table: \"_enumtable.users\""
    _enumtable_users_aggregate(
        "distinct select on columns"
        distinct_on: [_enumtable_users_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [_enumtable_users_order_by!],
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): _enumtable_users_aggregate!
    "fetch data from the table: \"_enumtable.users\" using primary key columns"
    _enumtable_users_by_pk(id: Int!): _enumtable_users
    "fetch data from the table in a streaming manner: \"_enumtable.users\""
    _enumtable_users_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [_enumtable_users_stream_cursor_input]!,
        "filter the rows returned"
        where: _enumtable_users_bool_exp
    ): [_enumtable_users!]!
    "fetch data from the table: \"buffgeom.objects\""
    buffgeom_objects(
        "distinct select on columns"
        distinct_on: [buffgeom_objects_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [buffgeom_objects_order_by!],
        "filter the rows returned"
        where: buffgeom_objects_bool_exp
    ): [buffgeom_objects!]!
    "fetch aggregated fields from the table: \"buffgeom.objects\""
    buffgeom_objects_aggregate(
        "distinct select on columns"
        distinct_on: [buffgeom_objects_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [buffgeom_objects_order_by!],
        "filter the rows returned"
        where: buffgeom_objects_bool_exp
    ): buffgeom_objects_aggregate!
    "fetch data from the table: \"buffgeom.objects\" using primary key columns"
    buffgeom_objects_by_pk(uuid: uuid!): buffgeom_objects
    "fetch data from the table in a streaming manner: \"buffgeom.objects\""
    buffgeom_objects_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [buffgeom_objects_stream_cursor_input]!,
        "filter the rows returned"
        where: buffgeom_objects_bool_exp
    ): [buffgeom_objects!]!
    "fetch data from the table: \"buffgeom.attributes\""
    geometry_attributes(
        "distinct select on columns"
        distinct_on: [geometry_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [geometry_attributes_order_by!],
        "filter the rows returned"
        where: geometry_attributes_bool_exp
    ): [geometry_attributes!]!
    "fetch aggregated fields from the table: \"buffgeom.attributes\""
    geometry_attributes_aggregate(
        "distinct select on columns"
        distinct_on: [geometry_attributes_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [geometry_attributes_order_by!],
        "filter the rows returned"
        where: geometry_attributes_bool_exp
    ): geometry_attributes_aggregate!
    "fetch data from the table: \"buffgeom.attributes\" using primary key columns"
    geometry_attributes_by_pk(uuid: uuid!): geometry_attributes
    "fetch data from the table in a streaming manner: \"buffgeom.attributes\""
    geometry_attributes_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [geometry_attributes_stream_cursor_input]!,
        "filter the rows returned"
        where: geometry_attributes_bool_exp
    ): [geometry_attributes!]!
    "fetch data from the table: \"lht_ceiling.properties\""
    lc_properties(
        "distinct select on columns"
        distinct_on: [lc_properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lc_properties_order_by!],
        "filter the rows returned"
        where: lc_properties_bool_exp
    ): [lc_properties!]!
    "fetch aggregated fields from the table: \"lht_ceiling.properties\""
    lc_properties_aggregate(
        "distinct select on columns"
        distinct_on: [lc_properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lc_properties_order_by!],
        "filter the rows returned"
        where: lc_properties_bool_exp
    ): lc_properties_aggregate!
    "fetch data from the table: \"lht_ceiling.properties\" using primary key columns"
    lc_properties_by_pk(id: Int!, subtype: String!, type: String!, uuid: uuid!): lc_properties
    "fetch data from the table in a streaming manner: \"lht_ceiling.properties\""
    lc_properties_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lc_properties_stream_cursor_input]!,
        "filter the rows returned"
        where: lc_properties_bool_exp
    ): [lc_properties!]!
    "fetch data from the table: \"lht_ceiling.panels\""
    lht_ceiling_panels(
        "distinct select on columns"
        distinct_on: [lht_ceiling_panels_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_panels_order_by!],
        "filter the rows returned"
        where: lht_ceiling_panels_bool_exp
    ): [lht_ceiling_panels!]!
    "fetch aggregated fields from the table: \"lht_ceiling.panels\""
    lht_ceiling_panels_aggregate(
        "distinct select on columns"
        distinct_on: [lht_ceiling_panels_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_panels_order_by!],
        "filter the rows returned"
        where: lht_ceiling_panels_bool_exp
    ): lht_ceiling_panels_aggregate!
    "fetch data from the table: \"lht_ceiling.panels\" using primary key columns"
    lht_ceiling_panels_by_pk(floor: String!, x: numeric!, y: numeric!): lht_ceiling_panels
    "fetch data from the table in a streaming manner: \"lht_ceiling.panels\""
    lht_ceiling_panels_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_ceiling_panels_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_ceiling_panels_bool_exp
    ): [lht_ceiling_panels!]!
    "fetch data from the table: \"lht_ceiling.type_marks\""
    lht_ceiling_type_marks(
        "distinct select on columns"
        distinct_on: [lht_ceiling_type_marks_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_type_marks_order_by!],
        "filter the rows returned"
        where: lht_ceiling_type_marks_bool_exp
    ): [lht_ceiling_type_marks!]!
    "fetch aggregated fields from the table: \"lht_ceiling.type_marks\""
    lht_ceiling_type_marks_aggregate(
        "distinct select on columns"
        distinct_on: [lht_ceiling_type_marks_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_ceiling_type_marks_order_by!],
        "filter the rows returned"
        where: lht_ceiling_type_marks_bool_exp
    ): lht_ceiling_type_marks_aggregate!
    "fetch data from the table: \"lht_ceiling.type_marks\" using primary key columns"
    lht_ceiling_type_marks_by_pk(x: numeric!, y: numeric!): lht_ceiling_type_marks
    "fetch data from the table in a streaming manner: \"lht_ceiling.type_marks\""
    lht_ceiling_type_marks_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_ceiling_type_marks_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_ceiling_type_marks_bool_exp
    ): [lht_ceiling_type_marks!]!
    "fetch data from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch aggregated fields from the table: \"lht_triangles.connectors\""
    lht_triangles_connectors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_connectors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_connectors_order_by!],
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): lht_triangles_connectors_aggregate!
    "fetch data from the table: \"lht_triangles.connectors\" using primary key columns"
    lht_triangles_connectors_by_pk(name: String!): lht_triangles_connectors
    "fetch data from the table in a streaming manner: \"lht_triangles.connectors\""
    lht_triangles_connectors_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_connectors_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_connectors_bool_exp
    ): [lht_triangles_connectors!]!
    "fetch data from the table: \"lht_triangles.contours\""
    lht_triangles_contours(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch aggregated fields from the table: \"lht_triangles.contours\""
    lht_triangles_contours_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_contours_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_contours_order_by!],
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): lht_triangles_contours_aggregate!
    "fetch data from the table: \"lht_triangles.contours\" using primary key columns"
    lht_triangles_contours_by_pk(uuid: uuid!): lht_triangles_contours
    "fetch data from the table in a streaming manner: \"lht_triangles.contours\""
    lht_triangles_contours_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_contours_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_contours_bool_exp
    ): [lht_triangles_contours!]!
    "fetch data from the table: \"lht_triangles.floors\""
    lht_triangles_floors(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch aggregated fields from the table: \"lht_triangles.floors\""
    lht_triangles_floors_aggregate(
        "distinct select on columns"
        distinct_on: [lht_triangles_floors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [lht_triangles_floors_order_by!],
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): lht_triangles_floors_aggregate!
    "fetch data from the table: \"lht_triangles.floors\" using primary key columns"
    lht_triangles_floors_by_pk(value: String!): lht_triangles_floors
    "fetch data from the table in a streaming manner: \"lht_triangles.floors\""
    lht_triangles_floors_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [lht_triangles_floors_stream_cursor_input]!,
        "filter the rows returned"
        where: lht_triangles_floors_bool_exp
    ): [lht_triangles_floors!]!
    "fetch data from the table: \"objects_hub\""
    objects_hub(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch aggregated fields from the table: \"objects_hub\""
    objects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    "fetch data from the table: \"objects_hub\" using primary key columns"
    objects_hub_by_pk(uuid: uuid!): objects_hub
    "fetch data from the table in a streaming manner: \"objects_hub\""
    objects_hub_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [objects_hub_stream_cursor_input]!,
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "fetch data from the table: \"presets.colors\""
    presets_colors(
        "distinct select on columns"
        distinct_on: [presets_colors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [presets_colors_order_by!],
        "filter the rows returned"
        where: presets_colors_bool_exp
    ): [presets_colors!]!
    "fetch aggregated fields from the table: \"presets.colors\""
    presets_colors_aggregate(
        "distinct select on columns"
        distinct_on: [presets_colors_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [presets_colors_order_by!],
        "filter the rows returned"
        where: presets_colors_bool_exp
    ): presets_colors_aggregate!
    "fetch data from the table: \"presets.colors\" using primary key columns"
    presets_colors_by_pk(id: Int!, palette: Int!): presets_colors
    "fetch data from the table in a streaming manner: \"presets.colors\""
    presets_colors_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [presets_colors_stream_cursor_input]!,
        "filter the rows returned"
        where: presets_colors_bool_exp
    ): [presets_colors!]!
    "fetch data from the table: \"projects.infographics_hub\""
    projects_infographics_hub(
        "distinct select on columns"
        distinct_on: [projects_infographics_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_infographics_hub_order_by!],
        "filter the rows returned"
        where: projects_infographics_hub_bool_exp
    ): [projects_infographics_hub!]!
    "fetch aggregated fields from the table: \"projects.infographics_hub\""
    projects_infographics_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_infographics_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_infographics_hub_order_by!],
        "filter the rows returned"
        where: projects_infographics_hub_bool_exp
    ): projects_infographics_hub_aggregate!
    "fetch data from the table: \"projects.infographics_hub\" using primary key columns"
    projects_infographics_hub_by_pk(id: uuid!): projects_infographics_hub
    "fetch data from the table in a streaming manner: \"projects.infographics_hub\""
    projects_infographics_hub_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [projects_infographics_hub_stream_cursor_input]!,
        "filter the rows returned"
        where: projects_infographics_hub_bool_exp
    ): [projects_infographics_hub!]!
    "fetch data from the table: \"projects.projects_hub\""
    projects_projects_hub(
        "distinct select on columns"
        distinct_on: [projects_projects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_projects_hub_order_by!],
        "filter the rows returned"
        where: projects_projects_hub_bool_exp
    ): [projects_projects_hub!]!
    "fetch aggregated fields from the table: \"projects.projects_hub\""
    projects_projects_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_projects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_projects_hub_order_by!],
        "filter the rows returned"
        where: projects_projects_hub_bool_exp
    ): projects_projects_hub_aggregate!
    "fetch data from the table: \"projects.projects_hub\" using primary key columns"
    projects_projects_hub_by_pk(id: uuid!): projects_projects_hub
    "fetch data from the table in a streaming manner: \"projects.projects_hub\""
    projects_projects_hub_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [projects_projects_hub_stream_cursor_input]!,
        "filter the rows returned"
        where: projects_projects_hub_bool_exp
    ): [projects_projects_hub!]!
    "fetch data from the table: \"projects.queries_hub\""
    projects_queries_hub(
        "distinct select on columns"
        distinct_on: [projects_queries_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_queries_hub_order_by!],
        "filter the rows returned"
        where: projects_queries_hub_bool_exp
    ): [projects_queries_hub!]!
    "fetch aggregated fields from the table: \"projects.queries_hub\""
    projects_queries_hub_aggregate(
        "distinct select on columns"
        distinct_on: [projects_queries_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [projects_queries_hub_order_by!],
        "filter the rows returned"
        where: projects_queries_hub_bool_exp
    ): projects_queries_hub_aggregate!
    "fetch data from the table: \"projects.queries_hub\" using primary key columns"
    projects_queries_hub_by_pk(id: uuid!): projects_queries_hub
    "fetch data from the table in a streaming manner: \"projects.queries_hub\""
    projects_queries_hub_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [projects_queries_hub_stream_cursor_input]!,
        "filter the rows returned"
        where: projects_queries_hub_bool_exp
    ): [projects_queries_hub!]!
    "fetch data from the table: \"tests.properties\""
    properties(
        "distinct select on columns"
        distinct_on: [properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [properties_order_by!],
        "filter the rows returned"
        where: properties_bool_exp
    ): [properties!]!
    "fetch aggregated fields from the table: \"tests.properties\""
    properties_aggregate(
        "distinct select on columns"
        distinct_on: [properties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [properties_order_by!],
        "filter the rows returned"
        where: properties_bool_exp
    ): properties_aggregate!
    "fetch data from the table: \"tests.properties\" using primary key columns"
    properties_by_pk(index: Int!, uuid: uuid!): properties
    "fetch data from the table in a streaming manner: \"tests.properties\""
    properties_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [properties_stream_cursor_input]!,
        "filter the rows returned"
        where: properties_bool_exp
    ): [properties!]!
    "fetch data from the table: \"threejs.types\""
    threejs_types(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
    "fetch aggregated fields from the table: \"threejs.types\""
    threejs_types_aggregate(
        "distinct select on columns"
        distinct_on: [threejs_types_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [threejs_types_order_by!],
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): threejs_types_aggregate!
    "fetch data from the table: \"threejs.types\" using primary key columns"
    threejs_types_by_pk(value: String!): threejs_types
    "fetch data from the table in a streaming manner: \"threejs.types\""
    threejs_types_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [threejs_types_stream_cursor_input]!,
        "filter the rows returned"
        where: threejs_types_bool_exp
    ): [threejs_types!]!
}

"columns and relationships of \"threejs.types\""
type threejs_types {
    comment: String
    "An array relationship"
    objects(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): [objects_hub!]!
    "An aggregate relationship"
    objects_aggregate(
        "distinct select on columns"
        distinct_on: [objects_hub_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [objects_hub_order_by!],
        "filter the rows returned"
        where: objects_hub_bool_exp
    ): objects_hub_aggregate!
    value: String!
}

"aggregated selection of \"threejs.types\""
type threejs_types_aggregate {
    aggregate: threejs_types_aggregate_fields
    nodes: [threejs_types!]!
}

"aggregate fields of \"threejs.types\""
type threejs_types_aggregate_fields {
    count(columns: [threejs_types_select_column!], distinct: Boolean): Int!
    max: threejs_types_max_fields
    min: threejs_types_min_fields
}

"aggregate max on columns"
type threejs_types_max_fields {
    comment: String
    value: String
}

"aggregate min on columns"
type threejs_types_min_fields {
    comment: String
    value: String
}

"response of any mutation on the table \"threejs.types\""
type threejs_types_mutation_response {
    "number of rows affected by the mutation"
    affected_rows: Int!
    "data from the rows affected by the mutation"
    returning: [threejs_types!]!
}

"unique or primary key constraints on table \"_enumtable.role\""
enum _enumtable_role_constraint {
    "unique or primary key constraint on columns \"value\""
    role_pkey
}

enum _enumtable_role_enum {
    Group
    InstanceMesh
    Mesh
    Object3d
    "An author who writes posts."
    author
    "An editor who edits and manages content."
    editor
}

"select columns of table \"_enumtable.role\""
enum _enumtable_role_select_column {
    "column name"
    comment
    "column name"
    value
}

"update columns of table \"_enumtable.role\""
enum _enumtable_role_update_column {
    "column name"
    comment
    "column name"
    value
}

"unique or primary key constraints on table \"_enumtable.users\""
enum _enumtable_users_constraint {
    "unique or primary key constraint on columns \"id\""
    users_pkey
}

"select columns of table \"_enumtable.users\""
enum _enumtable_users_select_column {
    "column name"
    id
    "column name"
    name
    "column name"
    type
}

"update columns of table \"_enumtable.users\""
enum _enumtable_users_update_column {
    "column name"
    id
    "column name"
    name
    "column name"
    type
}

"unique or primary key constraints on table \"buffgeom.objects\""
enum buffgeom_objects_constraint {
    "unique or primary key constraint on columns \"uuid\""
    objects_pkey
}

"select columns of table \"buffgeom.objects\""
enum buffgeom_objects_select_column {
    "column name"
    castShadow
    "column name"
    children
    "column name"
    geometry
    "column name"
    layers
    "column name"
    material
    "column name"
    matrix
    "column name"
    name
    "column name"
    receiveShadow
    "column name"
    type
    "column name"
    userData
    "column name"
    uuid
}

"update columns of table \"buffgeom.objects\""
enum buffgeom_objects_update_column {
    "column name"
    castShadow
    "column name"
    children
    "column name"
    geometry
    "column name"
    layers
    "column name"
    material
    "column name"
    matrix
    "column name"
    name
    "column name"
    receiveShadow
    "column name"
    type
    "column name"
    userData
    "column name"
    uuid
}

"ordering argument of a cursor"
enum cursor_ordering {
    "ascending ordering of the cursor"
    ASC
    "descending ordering of the cursor"
    DESC
}

"unique or primary key constraints on table \"buffgeom.attributes\""
enum geometry_attributes_constraint {
    "unique or primary key constraint on columns \"uuid\""
    attributes_pkey
    "unique or primary key constraint on columns \"uuid\""
    attributes_uuid_key
}

"select columns of table \"buffgeom.attributes\""
enum geometry_attributes_select_column {
    "column name"
    index
    "column name"
    normal
    "column name"
    position
    "column name"
    type
    "column name"
    uuid
    "column name"
    uv
}

"update columns of table \"buffgeom.attributes\""
enum geometry_attributes_update_column {
    "column name"
    index
    "column name"
    normal
    "column name"
    position
    "column name"
    type
    "column name"
    uuid
    "column name"
    uv
}

"unique or primary key constraints on table \"lht_ceiling.properties\""
enum lc_properties_constraint {
    "unique or primary key constraint on columns \"uuid\", \"id\""
    properties_id_uuid_key
    "unique or primary key constraint on columns \"type\", \"uuid\", \"id\", \"subtype\""
    properties_pkey
    "unique or primary key constraint on columns \"sss\""
    properties_sss_key
}

"select columns of table \"lht_ceiling.properties\""
enum lc_properties_select_column {
    "column name"
    id
    "column name"
    part
    "column name"
    sss
    "column name"
    stage
    "column name"
    status
    "column name"
    subtype
    "column name"
    type
    "column name"
    uuid
    "column name"
    zone
}

"update columns of table \"lht_ceiling.properties\""
enum lc_properties_update_column {
    "column name"
    id
    "column name"
    part
    "column name"
    sss
    "column name"
    stage
    "column name"
    status
    "column name"
    subtype
    "column name"
    type
    "column name"
    uuid
    "column name"
    zone
}

"unique or primary key constraints on table \"lht_ceiling.panels\""
enum lht_ceiling_panels_constraint {
    "unique or primary key constraint on columns \"id\""
    panels_id_key
    "unique or primary key constraint on columns \"x\", \"y\", \"floor\""
    panels_pkey
    "unique or primary key constraint on columns \"uuid\""
    panels_uuid_key
    "unique or primary key constraint on columns \"x\", \"y\", \"floor\""
    panels_x_y_floor_key
}

"select columns of table \"lht_ceiling.panels\""
enum lht_ceiling_panels_select_column {
    "column name"
    centroid
    "column name"
    cutted
    "column name"
    extra
    "column name"
    floor
    "column name"
    id
    "column name"
    mark
    "column name"
    mask
    "column name"
    matrix
    "column name"
    outside
    "column name"
    points
    "column name"
    stage
    "column name"
    stripe
    "column name"
    subtype
    "column name"
    tag
    "column name"
    updated_at
    "column name"
    uuid
    "column name"
    x
    "column name"
    y
}

"update columns of table \"lht_ceiling.panels\""
enum lht_ceiling_panels_update_column {
    "column name"
    centroid
    "column name"
    cutted
    "column name"
    extra
    "column name"
    floor
    "column name"
    id
    "column name"
    mark
    "column name"
    mask
    "column name"
    matrix
    "column name"
    outside
    "column name"
    points
    "column name"
    stage
    "column name"
    stripe
    "column name"
    subtype
    "column name"
    tag
    "column name"
    updated_at
    "column name"
    uuid
    "column name"
    x
    "column name"
    y
}

"unique or primary key constraints on table \"lht_ceiling.type_marks\""
enum lht_ceiling_type_marks_constraint {
    "unique or primary key constraint on columns \"x\", \"y\""
    type_marks_pkey
    "unique or primary key constraint on columns \"uuid\""
    type_marks_uuid_key
}

"select columns of table \"lht_ceiling.type_marks\""
enum lht_ceiling_type_marks_select_column {
    "column name"
    floor
    "column name"
    modify
    "column name"
    tag
    "column name"
    uuid
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"update columns of table \"lht_ceiling.type_marks\""
enum lht_ceiling_type_marks_update_column {
    "column name"
    floor
    "column name"
    modify
    "column name"
    tag
    "column name"
    uuid
    "column name"
    x
    "column name"
    y
    "column name"
    z
}

"unique or primary key constraints on table \"lht_triangles.connectors\""
enum lht_triangles_connectors_constraint {
    "unique or primary key constraint on columns \"name\""
    connectors_name_key
    "unique or primary key constraint on columns \"name\""
    connectors_pkey
}

"select columns of table \"lht_triangles.connectors\""
enum lht_triangles_connectors_select_column {
    "column name"
    from
    "column name"
    name
    "column name"
    offset
    "column name"
    production
    "column name"
    type
}

"update columns of table \"lht_triangles.connectors\""
enum lht_triangles_connectors_update_column {
    "column name"
    from
    "column name"
    name
    "column name"
    offset
    "column name"
    production
    "column name"
    type
}

"unique or primary key constraints on table \"lht_triangles.contours\""
enum lht_triangles_contours_constraint {
    "unique or primary key constraint on columns \"uuid\""
    all_pkey
}

"select columns of table \"lht_triangles.contours\""
enum lht_triangles_contours_select_column {
    "column name"
    curve
    "column name"
    detail
    "column name"
    floor
    "column name"
    uuid
}

"update columns of table \"lht_triangles.contours\""
enum lht_triangles_contours_update_column {
    "column name"
    curve
    "column name"
    detail
    "column name"
    floor
    "column name"
    uuid
}

"unique or primary key constraints on table \"lht_triangles.floors\""
enum lht_triangles_floors_constraint {
    "unique or primary key constraint on columns \"value\""
    floors_pkey
}

enum lht_triangles_floors_enum {
    B1
    L1
    L2
    L2W
}

"select columns of table \"lht_triangles.floors\""
enum lht_triangles_floors_select_column {
    "column name"
    comment
    "column name"
    value
}

"update columns of table \"lht_triangles.floors\""
enum lht_triangles_floors_update_column {
    "column name"
    comment
    "column name"
    value
}

"unique or primary key constraints on table \"objects_hub\""
enum objects_hub_constraint {
    "unique or primary key constraint on columns \"uuid\""
    objects_hub_pkey
}

"select columns of table \"objects_hub\""
enum objects_hub_select_column {
    "column name"
    children
    "column name"
    name
    "column name"
    type
    "column name"
    uuid
}

"update columns of table \"objects_hub\""
enum objects_hub_update_column {
    "column name"
    children
    "column name"
    name
    "column name"
    type
    "column name"
    uuid
}

"column ordering options"
enum order_by {
    "in ascending order, nulls last"
    asc
    "in ascending order, nulls first"
    asc_nulls_first
    "in ascending order, nulls last"
    asc_nulls_last
    "in descending order, nulls first"
    desc
    "in descending order, nulls first"
    desc_nulls_first
    "in descending order, nulls last"
    desc_nulls_last
}

"unique or primary key constraints on table \"presets.colors\""
enum presets_colors_constraint {
    "unique or primary key constraint on columns \"decimal\""
    colors_decimal_key
    "unique or primary key constraint on columns \"hex\""
    colors_hex_key
    "unique or primary key constraint on columns \"id\""
    colors_id_key
    "unique or primary key constraint on columns \"id\", \"palette\""
    colors_pkey
}

"select columns of table \"presets.colors\""
enum presets_colors_select_column {
    "column name"
    b
    "column name"
    decimal
    "column name"
    g
    "column name"
    hex
    "column name"
    id
    "column name"
    name
    "column name"
    palette
    "column name"
    r
}

"update columns of table \"presets.colors\""
enum presets_colors_update_column {
    "column name"
    b
    "column name"
    decimal
    "column name"
    g
    "column name"
    hex
    "column name"
    id
    "column name"
    name
    "column name"
    palette
    "column name"
    r
}

"unique or primary key constraints on table \"projects.infographics_hub\""
enum projects_infographics_hub_constraint {
    "unique or primary key constraint on columns \"id\""
    infographics_hub_pkey
}

"select columns of table \"projects.infographics_hub\""
enum projects_infographics_hub_select_column {
    "column name"
    body
    "column name"
    cr
    "column name"
    id
    "column name"
    name
    "column name"
    object_id
    "column name"
    project_name
}

"update columns of table \"projects.infographics_hub\""
enum projects_infographics_hub_update_column {
    "column name"
    body
    "column name"
    cr
    "column name"
    id
    "column name"
    name
    "column name"
    object_id
    "column name"
    project_name
}

"unique or primary key constraints on table \"projects.projects_hub\""
enum projects_projects_hub_constraint {
    "unique or primary key constraint on columns \"id\""
    projects_hub_pkey
}

"select columns of table \"projects.projects_hub\""
enum projects_projects_hub_select_column {
    "column name"
    id
    "column name"
    last_visited
    "column name"
    name
    "column name"
    thumb
}

"update columns of table \"projects.projects_hub\""
enum projects_projects_hub_update_column {
    "column name"
    id
    "column name"
    last_visited
    "column name"
    name
    "column name"
    thumb
}

"unique or primary key constraints on table \"projects.queries_hub\""
enum projects_queries_hub_constraint {
    "unique or primary key constraint on columns \"id\""
    queries_hub_pkey
}

"select columns of table \"projects.queries_hub\""
enum projects_queries_hub_select_column {
    "column name"
    body
    "column name"
    cr
    "column name"
    endpoint
    "column name"
    id
    "column name"
    name
    "column name"
    project_name
    "column name"
    tags
}

"update columns of table \"projects.queries_hub\""
enum projects_queries_hub_update_column {
    "column name"
    body
    "column name"
    cr
    "column name"
    endpoint
    "column name"
    id
    "column name"
    name
    "column name"
    project_name
    "column name"
    tags
}

"unique or primary key constraints on table \"tests.properties\""
enum properties_constraint {
    "unique or primary key constraint on columns \"index\""
    lht_tri_pnl_0_index_key
    "unique or primary key constraint on columns \"index\", \"uuid\""
    lht_tri_pnl_0_pkey
    "unique or primary key constraint on columns \"uuid\""
    lht_tri_pnl_0_uuid_key
}

"select columns of table \"tests.properties\""
enum properties_select_column {
    "column name"
    area
    "column name"
    index
    "column name"
    part
    "column name"
    stage
    "column name"
    status
    "column name"
    subtype
    "column name"
    type
    "column name"
    uuid
}

"update columns of table \"tests.properties\""
enum properties_update_column {
    "column name"
    area
    "column name"
    index
    "column name"
    part
    "column name"
    stage
    "column name"
    status
    "column name"
    subtype
    "column name"
    type
    "column name"
    uuid
}

"unique or primary key constraints on table \"threejs.types\""
enum threejs_types_constraint {
    "unique or primary key constraint on columns \"value\""
    types_pkey
}

"select columns of table \"threejs.types\""
enum threejs_types_select_column {
    "column name"
    comment
    "column name"
    value
}

"update columns of table \"threejs.types\""
enum threejs_types_update_column {
    "column name"
    comment
    "column name"
    value
}

"Scalar _Any"
scalar _Any

scalar jsonb

scalar name

scalar numeric

scalar oidvector

scalar timestamptz

scalar uuid

"Boolean expression to compare columns of type \"Boolean\". All fields are combined with logical 'AND'."
input Boolean_comparison_exp {
    _eq: Boolean
    _gt: Boolean
    _gte: Boolean
    _in: [Boolean!]
    _is_null: Boolean
    _lt: Boolean
    _lte: Boolean
    _neq: Boolean
    _nin: [Boolean!]
}

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
    _eq: Int
    _gt: Int
    _gte: Int
    _in: [Int!]
    _is_null: Boolean
    _lt: Int
    _lte: Int
    _neq: Int
    _nin: [Int!]
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    "does the column match the given case-insensitive pattern"
    _ilike: String
    _in: [String!]
    "does the column match the given POSIX regular expression, case insensitive"
    _iregex: String
    _is_null: Boolean
    "does the column match the given pattern"
    _like: String
    _lt: String
    _lte: String
    _neq: String
    "does the column NOT match the given case-insensitive pattern"
    _nilike: String
    _nin: [String!]
    "does the column NOT match the given POSIX regular expression, case insensitive"
    _niregex: String
    "does the column NOT match the given pattern"
    _nlike: String
    "does the column NOT match the given POSIX regular expression, case sensitive"
    _nregex: String
    "does the column NOT match the given SQL regular expression"
    _nsimilar: String
    "does the column match the given POSIX regular expression, case sensitive"
    _regex: String
    "does the column match the given SQL regular expression"
    _similar: String
}

"Boolean expression to filter rows from the table \"_enumtable.role\". All fields are combined with a logical 'AND'."
input _enumtable_role_bool_exp {
    _and: [_enumtable_role_bool_exp!]
    _not: _enumtable_role_bool_exp
    _or: [_enumtable_role_bool_exp!]
    comment: String_comparison_exp
    users: _enumtable_users_bool_exp
    users_aggregate: _enumtable_users_aggregate_bool_exp
    value: String_comparison_exp
}

"Boolean expression to compare columns of type \"_enumtable_role_enum\". All fields are combined with logical 'AND'."
input _enumtable_role_enum_comparison_exp {
    _eq: _enumtable_role_enum
    _in: [_enumtable_role_enum!]
    _is_null: Boolean
    _neq: _enumtable_role_enum
    _nin: [_enumtable_role_enum!]
}

"input type for inserting data into table \"_enumtable.role\""
input _enumtable_role_insert_input {
    comment: String
    users: _enumtable_users_arr_rel_insert_input
    value: String
}

"on_conflict condition type for table \"_enumtable.role\""
input _enumtable_role_on_conflict {
    constraint: _enumtable_role_constraint!
    update_columns: [_enumtable_role_update_column!]! = []
    where: _enumtable_role_bool_exp
}

"Ordering options when selecting data from \"_enumtable.role\"."
input _enumtable_role_order_by {
    comment: order_by
    users_aggregate: _enumtable_users_aggregate_order_by
    value: order_by
}

"primary key columns input for table: _enumtable.role"
input _enumtable_role_pk_columns_input {
    value: String!
}

"input type for updating data in table \"_enumtable.role\""
input _enumtable_role_set_input {
    comment: String
    value: String
}

"Streaming cursor of the table \"_enumtable_role\""
input _enumtable_role_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: _enumtable_role_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input _enumtable_role_stream_cursor_value_input {
    comment: String
    value: String
}

input _enumtable_role_updates {
    "sets the columns of the filtered rows to the given values"
    _set: _enumtable_role_set_input
    "filter the rows which have to be updated"
    where: _enumtable_role_bool_exp!
}

input _enumtable_users_aggregate_bool_exp {
    count: _enumtable_users_aggregate_bool_exp_count
}

input _enumtable_users_aggregate_bool_exp_count {
    arguments: [_enumtable_users_select_column!]
    distinct: Boolean
    filter: _enumtable_users_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"_enumtable.users\""
input _enumtable_users_aggregate_order_by {
    avg: _enumtable_users_avg_order_by
    count: order_by
    max: _enumtable_users_max_order_by
    min: _enumtable_users_min_order_by
    stddev: _enumtable_users_stddev_order_by
    stddev_pop: _enumtable_users_stddev_pop_order_by
    stddev_samp: _enumtable_users_stddev_samp_order_by
    sum: _enumtable_users_sum_order_by
    var_pop: _enumtable_users_var_pop_order_by
    var_samp: _enumtable_users_var_samp_order_by
    variance: _enumtable_users_variance_order_by
}

"input type for inserting array relation for remote table \"_enumtable.users\""
input _enumtable_users_arr_rel_insert_input {
    data: [_enumtable_users_insert_input!]!
    "upsert condition"
    on_conflict: _enumtable_users_on_conflict
}

"order by avg() on columns of table \"_enumtable.users\""
input _enumtable_users_avg_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"_enumtable.users\". All fields are combined with a logical 'AND'."
input _enumtable_users_bool_exp {
    _and: [_enumtable_users_bool_exp!]
    _not: _enumtable_users_bool_exp
    _or: [_enumtable_users_bool_exp!]
    id: Int_comparison_exp
    name: String_comparison_exp
    type: _enumtable_role_enum_comparison_exp
}

"input type for incrementing numeric columns in table \"_enumtable.users\""
input _enumtable_users_inc_input {
    id: Int
}

"input type for inserting data into table \"_enumtable.users\""
input _enumtable_users_insert_input {
    id: Int
    name: String
    type: _enumtable_role_enum
}

"order by max() on columns of table \"_enumtable.users\""
input _enumtable_users_max_order_by {
    id: order_by
    name: order_by
}

"order by min() on columns of table \"_enumtable.users\""
input _enumtable_users_min_order_by {
    id: order_by
    name: order_by
}

"on_conflict condition type for table \"_enumtable.users\""
input _enumtable_users_on_conflict {
    constraint: _enumtable_users_constraint!
    update_columns: [_enumtable_users_update_column!]! = []
    where: _enumtable_users_bool_exp
}

"Ordering options when selecting data from \"_enumtable.users\"."
input _enumtable_users_order_by {
    id: order_by
    name: order_by
    type: order_by
}

"primary key columns input for table: _enumtable.users"
input _enumtable_users_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"_enumtable.users\""
input _enumtable_users_set_input {
    id: Int
    name: String
    type: _enumtable_role_enum
}

"order by stddev() on columns of table \"_enumtable.users\""
input _enumtable_users_stddev_order_by {
    id: order_by
}

"order by stddev_pop() on columns of table \"_enumtable.users\""
input _enumtable_users_stddev_pop_order_by {
    id: order_by
}

"order by stddev_samp() on columns of table \"_enumtable.users\""
input _enumtable_users_stddev_samp_order_by {
    id: order_by
}

"Streaming cursor of the table \"_enumtable_users\""
input _enumtable_users_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: _enumtable_users_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input _enumtable_users_stream_cursor_value_input {
    id: Int
    name: String
    type: _enumtable_role_enum
}

"order by sum() on columns of table \"_enumtable.users\""
input _enumtable_users_sum_order_by {
    id: order_by
}

input _enumtable_users_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: _enumtable_users_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: _enumtable_users_set_input
    "filter the rows which have to be updated"
    where: _enumtable_users_bool_exp!
}

"order by var_pop() on columns of table \"_enumtable.users\""
input _enumtable_users_var_pop_order_by {
    id: order_by
}

"order by var_samp() on columns of table \"_enumtable.users\""
input _enumtable_users_var_samp_order_by {
    id: order_by
}

"order by variance() on columns of table \"_enumtable.users\""
input _enumtable_users_variance_order_by {
    id: order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input buffgeom_objects_append_input {
    children: jsonb
    matrix: jsonb
    userData: jsonb
}

"Boolean expression to filter rows from the table \"buffgeom.objects\". All fields are combined with a logical 'AND'."
input buffgeom_objects_bool_exp {
    _and: [buffgeom_objects_bool_exp!]
    _not: buffgeom_objects_bool_exp
    _or: [buffgeom_objects_bool_exp!]
    attributes: geometry_attributes_bool_exp
    castShadow: Boolean_comparison_exp
    children: jsonb_comparison_exp
    geometry: uuid_comparison_exp
    layers: Int_comparison_exp
    material: uuid_comparison_exp
    matrix: jsonb_comparison_exp
    name: String_comparison_exp
    receiveShadow: Boolean_comparison_exp
    type: String_comparison_exp
    userData: jsonb_comparison_exp
    uuid: uuid_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input buffgeom_objects_delete_at_path_input {
    children: [String!]
    matrix: [String!]
    userData: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input buffgeom_objects_delete_elem_input {
    children: Int
    matrix: Int
    userData: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input buffgeom_objects_delete_key_input {
    children: String
    matrix: String
    userData: String
}

"input type for incrementing numeric columns in table \"buffgeom.objects\""
input buffgeom_objects_inc_input {
    layers: Int
}

"input type for inserting data into table \"buffgeom.objects\""
input buffgeom_objects_insert_input {
    attributes: geometry_attributes_obj_rel_insert_input
    castShadow: Boolean
    children: jsonb
    geometry: uuid
    layers: Int
    material: uuid
    matrix: jsonb
    name: String
    receiveShadow: Boolean
    type: String
    userData: jsonb
    uuid: uuid
}

"on_conflict condition type for table \"buffgeom.objects\""
input buffgeom_objects_on_conflict {
    constraint: buffgeom_objects_constraint!
    update_columns: [buffgeom_objects_update_column!]! = []
    where: buffgeom_objects_bool_exp
}

"Ordering options when selecting data from \"buffgeom.objects\"."
input buffgeom_objects_order_by {
    attributes: geometry_attributes_order_by
    castShadow: order_by
    children: order_by
    geometry: order_by
    layers: order_by
    material: order_by
    matrix: order_by
    name: order_by
    receiveShadow: order_by
    type: order_by
    userData: order_by
    uuid: order_by
}

"primary key columns input for table: buffgeom.objects"
input buffgeom_objects_pk_columns_input {
    uuid: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input buffgeom_objects_prepend_input {
    children: jsonb
    matrix: jsonb
    userData: jsonb
}

"input type for updating data in table \"buffgeom.objects\""
input buffgeom_objects_set_input {
    castShadow: Boolean
    children: jsonb
    geometry: uuid
    layers: Int
    material: uuid
    matrix: jsonb
    name: String
    receiveShadow: Boolean
    type: String
    userData: jsonb
    uuid: uuid
}

"Streaming cursor of the table \"buffgeom_objects\""
input buffgeom_objects_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: buffgeom_objects_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input buffgeom_objects_stream_cursor_value_input {
    castShadow: Boolean
    children: jsonb
    geometry: uuid
    layers: Int
    material: uuid
    matrix: jsonb
    name: String
    receiveShadow: Boolean
    type: String
    userData: jsonb
    uuid: uuid
}

input buffgeom_objects_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: buffgeom_objects_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: buffgeom_objects_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: buffgeom_objects_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: buffgeom_objects_delete_key_input
    "increments the numeric columns with given value of the filtered values"
    _inc: buffgeom_objects_inc_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: buffgeom_objects_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: buffgeom_objects_set_input
    "filter the rows which have to be updated"
    where: buffgeom_objects_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input geometry_attributes_append_input {
    index: jsonb
    normal: jsonb
    position: jsonb
    uv: jsonb
}

"Boolean expression to filter rows from the table \"buffgeom.attributes\". All fields are combined with a logical 'AND'."
input geometry_attributes_bool_exp {
    _and: [geometry_attributes_bool_exp!]
    _not: geometry_attributes_bool_exp
    _or: [geometry_attributes_bool_exp!]
    index: jsonb_comparison_exp
    normal: jsonb_comparison_exp
    position: jsonb_comparison_exp
    type: String_comparison_exp
    uuid: uuid_comparison_exp
    uv: jsonb_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input geometry_attributes_delete_at_path_input {
    index: [String!]
    normal: [String!]
    position: [String!]
    uv: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input geometry_attributes_delete_elem_input {
    index: Int
    normal: Int
    position: Int
    uv: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input geometry_attributes_delete_key_input {
    index: String
    normal: String
    position: String
    uv: String
}

"input type for inserting data into table \"buffgeom.attributes\""
input geometry_attributes_insert_input {
    index: jsonb
    normal: jsonb
    position: jsonb
    type: String
    uuid: uuid
    uv: jsonb
}

"input type for inserting object relation for remote table \"buffgeom.attributes\""
input geometry_attributes_obj_rel_insert_input {
    data: geometry_attributes_insert_input!
    "upsert condition"
    on_conflict: geometry_attributes_on_conflict
}

"on_conflict condition type for table \"buffgeom.attributes\""
input geometry_attributes_on_conflict {
    constraint: geometry_attributes_constraint!
    update_columns: [geometry_attributes_update_column!]! = []
    where: geometry_attributes_bool_exp
}

"Ordering options when selecting data from \"buffgeom.attributes\"."
input geometry_attributes_order_by {
    index: order_by
    normal: order_by
    position: order_by
    type: order_by
    uuid: order_by
    uv: order_by
}

"primary key columns input for table: buffgeom.attributes"
input geometry_attributes_pk_columns_input {
    uuid: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input geometry_attributes_prepend_input {
    index: jsonb
    normal: jsonb
    position: jsonb
    uv: jsonb
}

"input type for updating data in table \"buffgeom.attributes\""
input geometry_attributes_set_input {
    index: jsonb
    normal: jsonb
    position: jsonb
    type: String
    uuid: uuid
    uv: jsonb
}

"Streaming cursor of the table \"geometry_attributes\""
input geometry_attributes_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: geometry_attributes_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input geometry_attributes_stream_cursor_value_input {
    index: jsonb
    normal: jsonb
    position: jsonb
    type: String
    uuid: uuid
    uv: jsonb
}

input geometry_attributes_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: geometry_attributes_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: geometry_attributes_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: geometry_attributes_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: geometry_attributes_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: geometry_attributes_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: geometry_attributes_set_input
    "filter the rows which have to be updated"
    where: geometry_attributes_bool_exp!
}

input jsonb_cast_exp {
    String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    _cast: jsonb_cast_exp
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

"Boolean expression to filter rows from the table \"lht_ceiling.properties\". All fields are combined with a logical 'AND'."
input lc_properties_bool_exp {
    _and: [lc_properties_bool_exp!]
    _not: lc_properties_bool_exp
    _or: [lc_properties_bool_exp!]
    id: Int_comparison_exp
    part: String_comparison_exp
    sss: Int_comparison_exp
    stage: String_comparison_exp
    status: String_comparison_exp
    subtype: String_comparison_exp
    type: String_comparison_exp
    uuid: uuid_comparison_exp
    zone: String_comparison_exp
}

"input type for incrementing numeric columns in table \"lht_ceiling.properties\""
input lc_properties_inc_input {
    id: Int
    sss: Int
}

"input type for inserting data into table \"lht_ceiling.properties\""
input lc_properties_insert_input {
    id: Int
    part: String
    sss: Int
    stage: String
    status: String
    subtype: String
    type: String
    uuid: uuid
    zone: String
}

"on_conflict condition type for table \"lht_ceiling.properties\""
input lc_properties_on_conflict {
    constraint: lc_properties_constraint!
    update_columns: [lc_properties_update_column!]! = []
    where: lc_properties_bool_exp
}

"Ordering options when selecting data from \"lht_ceiling.properties\"."
input lc_properties_order_by {
    id: order_by
    part: order_by
    sss: order_by
    stage: order_by
    status: order_by
    subtype: order_by
    type: order_by
    uuid: order_by
    zone: order_by
}

"primary key columns input for table: lht_ceiling.properties"
input lc_properties_pk_columns_input {
    id: Int!
    subtype: String!
    type: String!
    uuid: uuid!
}

"input type for updating data in table \"lht_ceiling.properties\""
input lc_properties_set_input {
    id: Int
    part: String
    sss: Int
    stage: String
    status: String
    subtype: String
    type: String
    uuid: uuid
    zone: String
}

"Streaming cursor of the table \"lc_properties\""
input lc_properties_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lc_properties_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lc_properties_stream_cursor_value_input {
    id: Int
    part: String
    sss: Int
    stage: String
    status: String
    subtype: String
    type: String
    uuid: uuid
    zone: String
}

input lc_properties_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: lc_properties_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: lc_properties_set_input
    "filter the rows which have to be updated"
    where: lc_properties_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input lht_ceiling_panels_append_input {
    centroid: jsonb
    matrix: jsonb
    points: jsonb
}

"Boolean expression to filter rows from the table \"lht_ceiling.panels\". All fields are combined with a logical 'AND'."
input lht_ceiling_panels_bool_exp {
    _and: [lht_ceiling_panels_bool_exp!]
    _not: lht_ceiling_panels_bool_exp
    _or: [lht_ceiling_panels_bool_exp!]
    centroid: jsonb_comparison_exp
    cutted: Boolean_comparison_exp
    dtype: lht_ceiling_type_marks_bool_exp
    extra: Boolean_comparison_exp
    floor: String_comparison_exp
    id: Int_comparison_exp
    mark: String_comparison_exp
    mask: Boolean_comparison_exp
    matrix: jsonb_comparison_exp
    outside: Boolean_comparison_exp
    points: jsonb_comparison_exp
    stage: String_comparison_exp
    stripe: Int_comparison_exp
    subtype: Int_comparison_exp
    tag: String_comparison_exp
    updated_at: timestamptz_comparison_exp
    uuid: uuid_comparison_exp
    x: numeric_comparison_exp
    y: numeric_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input lht_ceiling_panels_delete_at_path_input {
    centroid: [String!]
    matrix: [String!]
    points: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input lht_ceiling_panels_delete_elem_input {
    centroid: Int
    matrix: Int
    points: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input lht_ceiling_panels_delete_key_input {
    centroid: String
    matrix: String
    points: String
}

"input type for incrementing numeric columns in table \"lht_ceiling.panels\""
input lht_ceiling_panels_inc_input {
    id: Int
    stripe: Int
    subtype: Int
    x: numeric
    y: numeric
}

"input type for inserting data into table \"lht_ceiling.panels\""
input lht_ceiling_panels_insert_input {
    centroid: jsonb
    cutted: Boolean
    dtype: lht_ceiling_type_marks_obj_rel_insert_input
    extra: Boolean
    floor: String
    id: Int
    mark: String
    mask: Boolean
    matrix: jsonb
    outside: Boolean
    points: jsonb
    stage: String
    stripe: Int
    subtype: Int
    tag: String
    updated_at: timestamptz
    uuid: uuid
    x: numeric
    y: numeric
}

"on_conflict condition type for table \"lht_ceiling.panels\""
input lht_ceiling_panels_on_conflict {
    constraint: lht_ceiling_panels_constraint!
    update_columns: [lht_ceiling_panels_update_column!]! = []
    where: lht_ceiling_panels_bool_exp
}

"Ordering options when selecting data from \"lht_ceiling.panels\"."
input lht_ceiling_panels_order_by {
    centroid: order_by
    cutted: order_by
    dtype: lht_ceiling_type_marks_order_by
    extra: order_by
    floor: order_by
    id: order_by
    mark: order_by
    mask: order_by
    matrix: order_by
    outside: order_by
    points: order_by
    stage: order_by
    stripe: order_by
    subtype: order_by
    tag: order_by
    updated_at: order_by
    uuid: order_by
    x: order_by
    y: order_by
}

"primary key columns input for table: lht_ceiling.panels"
input lht_ceiling_panels_pk_columns_input {
    floor: String!
    x: numeric!
    y: numeric!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input lht_ceiling_panels_prepend_input {
    centroid: jsonb
    matrix: jsonb
    points: jsonb
}

"input type for updating data in table \"lht_ceiling.panels\""
input lht_ceiling_panels_set_input {
    centroid: jsonb
    cutted: Boolean
    extra: Boolean
    floor: String
    id: Int
    mark: String
    mask: Boolean
    matrix: jsonb
    outside: Boolean
    points: jsonb
    stage: String
    stripe: Int
    subtype: Int
    tag: String
    updated_at: timestamptz
    uuid: uuid
    x: numeric
    y: numeric
}

"Streaming cursor of the table \"lht_ceiling_panels\""
input lht_ceiling_panels_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_ceiling_panels_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_ceiling_panels_stream_cursor_value_input {
    centroid: jsonb
    cutted: Boolean
    extra: Boolean
    floor: String
    id: Int
    mark: String
    mask: Boolean
    matrix: jsonb
    outside: Boolean
    points: jsonb
    stage: String
    stripe: Int
    subtype: Int
    tag: String
    updated_at: timestamptz
    uuid: uuid
    x: numeric
    y: numeric
}

input lht_ceiling_panels_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: lht_ceiling_panels_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: lht_ceiling_panels_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: lht_ceiling_panels_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: lht_ceiling_panels_delete_key_input
    "increments the numeric columns with given value of the filtered values"
    _inc: lht_ceiling_panels_inc_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: lht_ceiling_panels_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_ceiling_panels_set_input
    "filter the rows which have to be updated"
    where: lht_ceiling_panels_bool_exp!
}

"Boolean expression to filter rows from the table \"lht_ceiling.type_marks\". All fields are combined with a logical 'AND'."
input lht_ceiling_type_marks_bool_exp {
    _and: [lht_ceiling_type_marks_bool_exp!]
    _not: lht_ceiling_type_marks_bool_exp
    _or: [lht_ceiling_type_marks_bool_exp!]
    floor: String_comparison_exp
    modify: timestamptz_comparison_exp
    tag: String_comparison_exp
    uuid: uuid_comparison_exp
    x: numeric_comparison_exp
    y: numeric_comparison_exp
    z: numeric_comparison_exp
}

"input type for incrementing numeric columns in table \"lht_ceiling.type_marks\""
input lht_ceiling_type_marks_inc_input {
    x: numeric
    y: numeric
    z: numeric
}

"input type for inserting data into table \"lht_ceiling.type_marks\""
input lht_ceiling_type_marks_insert_input {
    floor: String
    modify: timestamptz
    tag: String
    uuid: uuid
    x: numeric
    y: numeric
    z: numeric
}

"input type for inserting object relation for remote table \"lht_ceiling.type_marks\""
input lht_ceiling_type_marks_obj_rel_insert_input {
    data: lht_ceiling_type_marks_insert_input!
    "upsert condition"
    on_conflict: lht_ceiling_type_marks_on_conflict
}

"on_conflict condition type for table \"lht_ceiling.type_marks\""
input lht_ceiling_type_marks_on_conflict {
    constraint: lht_ceiling_type_marks_constraint!
    update_columns: [lht_ceiling_type_marks_update_column!]! = []
    where: lht_ceiling_type_marks_bool_exp
}

"Ordering options when selecting data from \"lht_ceiling.type_marks\"."
input lht_ceiling_type_marks_order_by {
    floor: order_by
    modify: order_by
    tag: order_by
    uuid: order_by
    x: order_by
    y: order_by
    z: order_by
}

"primary key columns input for table: lht_ceiling.type_marks"
input lht_ceiling_type_marks_pk_columns_input {
    x: numeric!
    y: numeric!
}

"input type for updating data in table \"lht_ceiling.type_marks\""
input lht_ceiling_type_marks_set_input {
    floor: String
    modify: timestamptz
    tag: String
    uuid: uuid
    x: numeric
    y: numeric
    z: numeric
}

"Streaming cursor of the table \"lht_ceiling_type_marks\""
input lht_ceiling_type_marks_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_ceiling_type_marks_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_ceiling_type_marks_stream_cursor_value_input {
    floor: String
    modify: timestamptz
    tag: String
    uuid: uuid
    x: numeric
    y: numeric
    z: numeric
}

input lht_ceiling_type_marks_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: lht_ceiling_type_marks_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_ceiling_type_marks_set_input
    "filter the rows which have to be updated"
    where: lht_ceiling_type_marks_bool_exp!
}

"Boolean expression to filter rows from the table \"lht_triangles.connectors\". All fields are combined with a logical 'AND'."
input lht_triangles_connectors_bool_exp {
    _and: [lht_triangles_connectors_bool_exp!]
    _not: lht_triangles_connectors_bool_exp
    _or: [lht_triangles_connectors_bool_exp!]
    contours: lht_triangles_contours_bool_exp
    contours_aggregate: lht_triangles_contours_aggregate_bool_exp
    from: String_comparison_exp
    name: String_comparison_exp
    offset: numeric_comparison_exp
    production: String_comparison_exp
    type: String_comparison_exp
}

"input type for incrementing numeric columns in table \"lht_triangles.connectors\""
input lht_triangles_connectors_inc_input {
    offset: numeric
}

"input type for inserting data into table \"lht_triangles.connectors\""
input lht_triangles_connectors_insert_input {
    contours: lht_triangles_contours_arr_rel_insert_input
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"input type for inserting object relation for remote table \"lht_triangles.connectors\""
input lht_triangles_connectors_obj_rel_insert_input {
    data: lht_triangles_connectors_insert_input!
    "upsert condition"
    on_conflict: lht_triangles_connectors_on_conflict
}

"on_conflict condition type for table \"lht_triangles.connectors\""
input lht_triangles_connectors_on_conflict {
    constraint: lht_triangles_connectors_constraint!
    update_columns: [lht_triangles_connectors_update_column!]! = []
    where: lht_triangles_connectors_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.connectors\"."
input lht_triangles_connectors_order_by {
    contours_aggregate: lht_triangles_contours_aggregate_order_by
    from: order_by
    name: order_by
    offset: order_by
    production: order_by
    type: order_by
}

"primary key columns input for table: lht_triangles.connectors"
input lht_triangles_connectors_pk_columns_input {
    name: String!
}

"input type for updating data in table \"lht_triangles.connectors\""
input lht_triangles_connectors_set_input {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

"Streaming cursor of the table \"lht_triangles_connectors\""
input lht_triangles_connectors_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_connectors_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_connectors_stream_cursor_value_input {
    from: String
    name: String
    offset: numeric
    production: String
    type: String
}

input lht_triangles_connectors_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: lht_triangles_connectors_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_connectors_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_connectors_bool_exp!
}

input lht_triangles_contours_aggregate_bool_exp {
    count: lht_triangles_contours_aggregate_bool_exp_count
}

input lht_triangles_contours_aggregate_bool_exp_count {
    arguments: [lht_triangles_contours_select_column!]
    distinct: Boolean
    filter: lht_triangles_contours_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"lht_triangles.contours\""
input lht_triangles_contours_aggregate_order_by {
    count: order_by
    max: lht_triangles_contours_max_order_by
    min: lht_triangles_contours_min_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_contours_append_input {
    curve: jsonb
}

"input type for inserting array relation for remote table \"lht_triangles.contours\""
input lht_triangles_contours_arr_rel_insert_input {
    data: [lht_triangles_contours_insert_input!]!
    "upsert condition"
    on_conflict: lht_triangles_contours_on_conflict
}

"Boolean expression to filter rows from the table \"lht_triangles.contours\". All fields are combined with a logical 'AND'."
input lht_triangles_contours_bool_exp {
    _and: [lht_triangles_contours_bool_exp!]
    _not: lht_triangles_contours_bool_exp
    _or: [lht_triangles_contours_bool_exp!]
    connector: lht_triangles_connectors_bool_exp
    curve: jsonb_comparison_exp
    detail: name_comparison_exp
    floor: lht_triangles_floors_enum_comparison_exp
    floorByFloor: lht_triangles_floors_bool_exp
    uuid: uuid_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input lht_triangles_contours_delete_at_path_input {
    curve: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input lht_triangles_contours_delete_elem_input {
    curve: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input lht_triangles_contours_delete_key_input {
    curve: String
}

"input type for inserting data into table \"lht_triangles.contours\""
input lht_triangles_contours_insert_input {
    connector: lht_triangles_connectors_obj_rel_insert_input
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    floorByFloor: lht_triangles_floors_obj_rel_insert_input
    uuid: uuid
}

"order by max() on columns of table \"lht_triangles.contours\""
input lht_triangles_contours_max_order_by {
    uuid: order_by
}

"order by min() on columns of table \"lht_triangles.contours\""
input lht_triangles_contours_min_order_by {
    uuid: order_by
}

"on_conflict condition type for table \"lht_triangles.contours\""
input lht_triangles_contours_on_conflict {
    constraint: lht_triangles_contours_constraint!
    update_columns: [lht_triangles_contours_update_column!]! = []
    where: lht_triangles_contours_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.contours\"."
input lht_triangles_contours_order_by {
    connector: lht_triangles_connectors_order_by
    curve: order_by
    detail: order_by
    floor: order_by
    floorByFloor: lht_triangles_floors_order_by
    uuid: order_by
}

"primary key columns input for table: lht_triangles.contours"
input lht_triangles_contours_pk_columns_input {
    uuid: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input lht_triangles_contours_prepend_input {
    curve: jsonb
}

"input type for updating data in table \"lht_triangles.contours\""
input lht_triangles_contours_set_input {
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    uuid: uuid
}

"Streaming cursor of the table \"lht_triangles_contours\""
input lht_triangles_contours_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_contours_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_contours_stream_cursor_value_input {
    curve: jsonb
    detail: name
    floor: lht_triangles_floors_enum
    uuid: uuid
}

input lht_triangles_contours_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: lht_triangles_contours_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: lht_triangles_contours_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: lht_triangles_contours_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: lht_triangles_contours_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: lht_triangles_contours_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_contours_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_contours_bool_exp!
}

"Boolean expression to filter rows from the table \"lht_triangles.floors\". All fields are combined with a logical 'AND'."
input lht_triangles_floors_bool_exp {
    _and: [lht_triangles_floors_bool_exp!]
    _not: lht_triangles_floors_bool_exp
    _or: [lht_triangles_floors_bool_exp!]
    comment: String_comparison_exp
    entities: lht_triangles_contours_bool_exp
    entities_aggregate: lht_triangles_contours_aggregate_bool_exp
    value: String_comparison_exp
}

"Boolean expression to compare columns of type \"lht_triangles_floors_enum\". All fields are combined with logical 'AND'."
input lht_triangles_floors_enum_comparison_exp {
    _eq: lht_triangles_floors_enum
    _in: [lht_triangles_floors_enum!]
    _is_null: Boolean
    _neq: lht_triangles_floors_enum
    _nin: [lht_triangles_floors_enum!]
}

"input type for inserting data into table \"lht_triangles.floors\""
input lht_triangles_floors_insert_input {
    comment: String
    entities: lht_triangles_contours_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"lht_triangles.floors\""
input lht_triangles_floors_obj_rel_insert_input {
    data: lht_triangles_floors_insert_input!
    "upsert condition"
    on_conflict: lht_triangles_floors_on_conflict
}

"on_conflict condition type for table \"lht_triangles.floors\""
input lht_triangles_floors_on_conflict {
    constraint: lht_triangles_floors_constraint!
    update_columns: [lht_triangles_floors_update_column!]! = []
    where: lht_triangles_floors_bool_exp
}

"Ordering options when selecting data from \"lht_triangles.floors\"."
input lht_triangles_floors_order_by {
    comment: order_by
    entities_aggregate: lht_triangles_contours_aggregate_order_by
    value: order_by
}

"primary key columns input for table: lht_triangles.floors"
input lht_triangles_floors_pk_columns_input {
    value: String!
}

"input type for updating data in table \"lht_triangles.floors\""
input lht_triangles_floors_set_input {
    comment: String
    value: String
}

"Streaming cursor of the table \"lht_triangles_floors\""
input lht_triangles_floors_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: lht_triangles_floors_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input lht_triangles_floors_stream_cursor_value_input {
    comment: String
    value: String
}

input lht_triangles_floors_updates {
    "sets the columns of the filtered rows to the given values"
    _set: lht_triangles_floors_set_input
    "filter the rows which have to be updated"
    where: lht_triangles_floors_bool_exp!
}

"Boolean expression to compare columns of type \"name\". All fields are combined with logical 'AND'."
input name_comparison_exp {
    _eq: name
    _gt: name
    _gte: name
    _in: [name!]
    _is_null: Boolean
    _lt: name
    _lte: name
    _neq: name
    _nin: [name!]
}

"Boolean expression to compare columns of type \"numeric\". All fields are combined with logical 'AND'."
input numeric_comparison_exp {
    _eq: numeric
    _gt: numeric
    _gte: numeric
    _in: [numeric!]
    _is_null: Boolean
    _lt: numeric
    _lte: numeric
    _neq: numeric
    _nin: [numeric!]
}

input objects_hub_aggregate_bool_exp {
    count: objects_hub_aggregate_bool_exp_count
}

input objects_hub_aggregate_bool_exp_count {
    arguments: [objects_hub_select_column!]
    distinct: Boolean
    filter: objects_hub_bool_exp
    predicate: Int_comparison_exp!
}

"order by aggregate values of table \"objects_hub\""
input objects_hub_aggregate_order_by {
    count: order_by
    max: objects_hub_max_order_by
    min: objects_hub_min_order_by
}

"input type for inserting array relation for remote table \"objects_hub\""
input objects_hub_arr_rel_insert_input {
    data: [objects_hub_insert_input!]!
    "upsert condition"
    on_conflict: objects_hub_on_conflict
}

"Boolean expression to filter rows from the table \"objects_hub\". All fields are combined with a logical 'AND'."
input objects_hub_bool_exp {
    _and: [objects_hub_bool_exp!]
    _not: objects_hub_bool_exp
    _or: [objects_hub_bool_exp!]
    children: oidvector_comparison_exp
    name: String_comparison_exp
    type: String_comparison_exp
    type_relay: threejs_types_bool_exp
    uuid: uuid_comparison_exp
}

"input type for inserting data into table \"objects_hub\""
input objects_hub_insert_input {
    children: oidvector
    name: String
    type: String
    type_relay: threejs_types_obj_rel_insert_input
    uuid: uuid
}

"order by max() on columns of table \"objects_hub\""
input objects_hub_max_order_by {
    name: order_by
    type: order_by
    uuid: order_by
}

"order by min() on columns of table \"objects_hub\""
input objects_hub_min_order_by {
    name: order_by
    type: order_by
    uuid: order_by
}

"on_conflict condition type for table \"objects_hub\""
input objects_hub_on_conflict {
    constraint: objects_hub_constraint!
    update_columns: [objects_hub_update_column!]! = []
    where: objects_hub_bool_exp
}

"Ordering options when selecting data from \"objects_hub\"."
input objects_hub_order_by {
    children: order_by
    name: order_by
    type: order_by
    type_relay: threejs_types_order_by
    uuid: order_by
}

"primary key columns input for table: objects_hub"
input objects_hub_pk_columns_input {
    uuid: uuid!
}

"input type for updating data in table \"objects_hub\""
input objects_hub_set_input {
    children: oidvector
    name: String
    type: String
    uuid: uuid
}

"Streaming cursor of the table \"objects_hub\""
input objects_hub_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: objects_hub_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input objects_hub_stream_cursor_value_input {
    children: oidvector
    name: String
    type: String
    uuid: uuid
}

input objects_hub_updates {
    "sets the columns of the filtered rows to the given values"
    _set: objects_hub_set_input
    "filter the rows which have to be updated"
    where: objects_hub_bool_exp!
}

"Boolean expression to compare columns of type \"oidvector\". All fields are combined with logical 'AND'."
input oidvector_comparison_exp {
    _eq: oidvector
    _gt: oidvector
    _gte: oidvector
    _in: [oidvector!]
    _is_null: Boolean
    _lt: oidvector
    _lte: oidvector
    _neq: oidvector
    _nin: [oidvector!]
}

"Boolean expression to filter rows from the table \"presets.colors\". All fields are combined with a logical 'AND'."
input presets_colors_bool_exp {
    _and: [presets_colors_bool_exp!]
    _not: presets_colors_bool_exp
    _or: [presets_colors_bool_exp!]
    b: Int_comparison_exp
    decimal: Int_comparison_exp
    g: Int_comparison_exp
    hex: String_comparison_exp
    id: Int_comparison_exp
    name: name_comparison_exp
    palette: Int_comparison_exp
    r: Int_comparison_exp
}

"input type for incrementing numeric columns in table \"presets.colors\""
input presets_colors_inc_input {
    b: Int
    decimal: Int
    g: Int
    id: Int
    palette: Int
    r: Int
}

"input type for inserting data into table \"presets.colors\""
input presets_colors_insert_input {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int
    name: name
    palette: Int
    r: Int
}

"on_conflict condition type for table \"presets.colors\""
input presets_colors_on_conflict {
    constraint: presets_colors_constraint!
    update_columns: [presets_colors_update_column!]! = []
    where: presets_colors_bool_exp
}

"Ordering options when selecting data from \"presets.colors\"."
input presets_colors_order_by {
    b: order_by
    decimal: order_by
    g: order_by
    hex: order_by
    id: order_by
    name: order_by
    palette: order_by
    r: order_by
}

"primary key columns input for table: presets.colors"
input presets_colors_pk_columns_input {
    id: Int!
    palette: Int!
}

"input type for updating data in table \"presets.colors\""
input presets_colors_set_input {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int
    name: name
    palette: Int
    r: Int
}

"Streaming cursor of the table \"presets_colors\""
input presets_colors_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: presets_colors_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input presets_colors_stream_cursor_value_input {
    b: Int
    decimal: Int
    g: Int
    hex: String
    id: Int
    name: name
    palette: Int
    r: Int
}

input presets_colors_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: presets_colors_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: presets_colors_set_input
    "filter the rows which have to be updated"
    where: presets_colors_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input projects_infographics_hub_append_input {
    body: jsonb
}

"Boolean expression to filter rows from the table \"projects.infographics_hub\". All fields are combined with a logical 'AND'."
input projects_infographics_hub_bool_exp {
    _and: [projects_infographics_hub_bool_exp!]
    _not: projects_infographics_hub_bool_exp
    _or: [projects_infographics_hub_bool_exp!]
    body: jsonb_comparison_exp
    cr: timestamptz_comparison_exp
    id: uuid_comparison_exp
    name: String_comparison_exp
    object_id: Int_comparison_exp
    project_name: String_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input projects_infographics_hub_delete_at_path_input {
    body: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input projects_infographics_hub_delete_elem_input {
    body: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input projects_infographics_hub_delete_key_input {
    body: String
}

"input type for incrementing numeric columns in table \"projects.infographics_hub\""
input projects_infographics_hub_inc_input {
    object_id: Int
}

"input type for inserting data into table \"projects.infographics_hub\""
input projects_infographics_hub_insert_input {
    body: jsonb
    cr: timestamptz
    id: uuid
    name: String
    object_id: Int
    project_name: String
}

"on_conflict condition type for table \"projects.infographics_hub\""
input projects_infographics_hub_on_conflict {
    constraint: projects_infographics_hub_constraint!
    update_columns: [projects_infographics_hub_update_column!]! = []
    where: projects_infographics_hub_bool_exp
}

"Ordering options when selecting data from \"projects.infographics_hub\"."
input projects_infographics_hub_order_by {
    body: order_by
    cr: order_by
    id: order_by
    name: order_by
    object_id: order_by
    project_name: order_by
}

"primary key columns input for table: projects.infographics_hub"
input projects_infographics_hub_pk_columns_input {
    id: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input projects_infographics_hub_prepend_input {
    body: jsonb
}

"input type for updating data in table \"projects.infographics_hub\""
input projects_infographics_hub_set_input {
    body: jsonb
    cr: timestamptz
    id: uuid
    name: String
    object_id: Int
    project_name: String
}

"Streaming cursor of the table \"projects_infographics_hub\""
input projects_infographics_hub_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: projects_infographics_hub_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input projects_infographics_hub_stream_cursor_value_input {
    body: jsonb
    cr: timestamptz
    id: uuid
    name: String
    object_id: Int
    project_name: String
}

input projects_infographics_hub_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: projects_infographics_hub_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: projects_infographics_hub_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: projects_infographics_hub_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: projects_infographics_hub_delete_key_input
    "increments the numeric columns with given value of the filtered values"
    _inc: projects_infographics_hub_inc_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: projects_infographics_hub_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: projects_infographics_hub_set_input
    "filter the rows which have to be updated"
    where: projects_infographics_hub_bool_exp!
}

"Boolean expression to filter rows from the table \"projects.projects_hub\". All fields are combined with a logical 'AND'."
input projects_projects_hub_bool_exp {
    _and: [projects_projects_hub_bool_exp!]
    _not: projects_projects_hub_bool_exp
    _or: [projects_projects_hub_bool_exp!]
    id: uuid_comparison_exp
    last_visited: timestamptz_comparison_exp
    name: String_comparison_exp
    thumb: String_comparison_exp
}

"input type for inserting data into table \"projects.projects_hub\""
input projects_projects_hub_insert_input {
    id: uuid
    last_visited: timestamptz
    name: String
    thumb: String
}

"on_conflict condition type for table \"projects.projects_hub\""
input projects_projects_hub_on_conflict {
    constraint: projects_projects_hub_constraint!
    update_columns: [projects_projects_hub_update_column!]! = []
    where: projects_projects_hub_bool_exp
}

"Ordering options when selecting data from \"projects.projects_hub\"."
input projects_projects_hub_order_by {
    id: order_by
    last_visited: order_by
    name: order_by
    thumb: order_by
}

"primary key columns input for table: projects.projects_hub"
input projects_projects_hub_pk_columns_input {
    id: uuid!
}

"input type for updating data in table \"projects.projects_hub\""
input projects_projects_hub_set_input {
    id: uuid
    last_visited: timestamptz
    name: String
    thumb: String
}

"Streaming cursor of the table \"projects_projects_hub\""
input projects_projects_hub_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: projects_projects_hub_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input projects_projects_hub_stream_cursor_value_input {
    id: uuid
    last_visited: timestamptz
    name: String
    thumb: String
}

input projects_projects_hub_updates {
    "sets the columns of the filtered rows to the given values"
    _set: projects_projects_hub_set_input
    "filter the rows which have to be updated"
    where: projects_projects_hub_bool_exp!
}

"append existing jsonb value of filtered columns with new jsonb value"
input projects_queries_hub_append_input {
    body: jsonb
    tags: jsonb
}

"Boolean expression to filter rows from the table \"projects.queries_hub\". All fields are combined with a logical 'AND'."
input projects_queries_hub_bool_exp {
    _and: [projects_queries_hub_bool_exp!]
    _not: projects_queries_hub_bool_exp
    _or: [projects_queries_hub_bool_exp!]
    body: jsonb_comparison_exp
    cr: timestamptz_comparison_exp
    endpoint: String_comparison_exp
    id: uuid_comparison_exp
    name: String_comparison_exp
    project_name: String_comparison_exp
    tags: jsonb_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input projects_queries_hub_delete_at_path_input {
    body: [String!]
    tags: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input projects_queries_hub_delete_elem_input {
    body: Int
    tags: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input projects_queries_hub_delete_key_input {
    body: String
    tags: String
}

"input type for inserting data into table \"projects.queries_hub\""
input projects_queries_hub_insert_input {
    body: jsonb
    cr: timestamptz
    endpoint: String
    id: uuid
    name: String
    project_name: String
    tags: jsonb
}

"on_conflict condition type for table \"projects.queries_hub\""
input projects_queries_hub_on_conflict {
    constraint: projects_queries_hub_constraint!
    update_columns: [projects_queries_hub_update_column!]! = []
    where: projects_queries_hub_bool_exp
}

"Ordering options when selecting data from \"projects.queries_hub\"."
input projects_queries_hub_order_by {
    body: order_by
    cr: order_by
    endpoint: order_by
    id: order_by
    name: order_by
    project_name: order_by
    tags: order_by
}

"primary key columns input for table: projects.queries_hub"
input projects_queries_hub_pk_columns_input {
    id: uuid!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input projects_queries_hub_prepend_input {
    body: jsonb
    tags: jsonb
}

"input type for updating data in table \"projects.queries_hub\""
input projects_queries_hub_set_input {
    body: jsonb
    cr: timestamptz
    endpoint: String
    id: uuid
    name: String
    project_name: String
    tags: jsonb
}

"Streaming cursor of the table \"projects_queries_hub\""
input projects_queries_hub_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: projects_queries_hub_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input projects_queries_hub_stream_cursor_value_input {
    body: jsonb
    cr: timestamptz
    endpoint: String
    id: uuid
    name: String
    project_name: String
    tags: jsonb
}

input projects_queries_hub_updates {
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: projects_queries_hub_append_input
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: projects_queries_hub_delete_at_path_input
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: projects_queries_hub_delete_elem_input
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: projects_queries_hub_delete_key_input
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: projects_queries_hub_prepend_input
    "sets the columns of the filtered rows to the given values"
    _set: projects_queries_hub_set_input
    "filter the rows which have to be updated"
    where: projects_queries_hub_bool_exp!
}

"Boolean expression to filter rows from the table \"tests.properties\". All fields are combined with a logical 'AND'."
input properties_bool_exp {
    _and: [properties_bool_exp!]
    _not: properties_bool_exp
    _or: [properties_bool_exp!]
    area: numeric_comparison_exp
    index: Int_comparison_exp
    part: String_comparison_exp
    stage: String_comparison_exp
    status: String_comparison_exp
    subtype: Int_comparison_exp
    type: String_comparison_exp
    uuid: uuid_comparison_exp
}

"input type for incrementing numeric columns in table \"tests.properties\""
input properties_inc_input {
    area: numeric
    index: Int
    subtype: Int
}

"input type for inserting data into table \"tests.properties\""
input properties_insert_input {
    area: numeric
    index: Int
    part: String
    stage: String
    status: String
    subtype: Int
    type: String
    uuid: uuid
}

"on_conflict condition type for table \"tests.properties\""
input properties_on_conflict {
    constraint: properties_constraint!
    update_columns: [properties_update_column!]! = []
    where: properties_bool_exp
}

"Ordering options when selecting data from \"tests.properties\"."
input properties_order_by {
    area: order_by
    index: order_by
    part: order_by
    stage: order_by
    status: order_by
    subtype: order_by
    type: order_by
    uuid: order_by
}

"primary key columns input for table: tests.properties"
input properties_pk_columns_input {
    index: Int!
    uuid: uuid!
}

"input type for updating data in table \"tests.properties\""
input properties_set_input {
    area: numeric
    index: Int
    part: String
    stage: String
    status: String
    subtype: Int
    type: String
    uuid: uuid
}

"Streaming cursor of the table \"properties\""
input properties_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: properties_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input properties_stream_cursor_value_input {
    area: numeric
    index: Int
    part: String
    stage: String
    status: String
    subtype: Int
    type: String
    uuid: uuid
}

input properties_updates {
    "increments the numeric columns with given value of the filtered values"
    _inc: properties_inc_input
    "sets the columns of the filtered rows to the given values"
    _set: properties_set_input
    "filter the rows which have to be updated"
    where: properties_bool_exp!
}

"Boolean expression to filter rows from the table \"threejs.types\". All fields are combined with a logical 'AND'."
input threejs_types_bool_exp {
    _and: [threejs_types_bool_exp!]
    _not: threejs_types_bool_exp
    _or: [threejs_types_bool_exp!]
    comment: String_comparison_exp
    objects: objects_hub_bool_exp
    objects_aggregate: objects_hub_aggregate_bool_exp
    value: String_comparison_exp
}

"input type for inserting data into table \"threejs.types\""
input threejs_types_insert_input {
    comment: String
    objects: objects_hub_arr_rel_insert_input
    value: String
}

"input type for inserting object relation for remote table \"threejs.types\""
input threejs_types_obj_rel_insert_input {
    data: threejs_types_insert_input!
    "upsert condition"
    on_conflict: threejs_types_on_conflict
}

"on_conflict condition type for table \"threejs.types\""
input threejs_types_on_conflict {
    constraint: threejs_types_constraint!
    update_columns: [threejs_types_update_column!]! = []
    where: threejs_types_bool_exp
}

"Ordering options when selecting data from \"threejs.types\"."
input threejs_types_order_by {
    comment: order_by
    objects_aggregate: objects_hub_aggregate_order_by
    value: order_by
}

"primary key columns input for table: threejs.types"
input threejs_types_pk_columns_input {
    value: String!
}

"input type for updating data in table \"threejs.types\""
input threejs_types_set_input {
    comment: String
    value: String
}

"Streaming cursor of the table \"threejs_types\""
input threejs_types_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: threejs_types_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input threejs_types_stream_cursor_value_input {
    comment: String
    value: String
}

input threejs_types_updates {
    "sets the columns of the filtered rows to the given values"
    _set: threejs_types_set_input
    "filter the rows which have to be updated"
    where: threejs_types_bool_exp!
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"Boolean expression to compare columns of type \"uuid\". All fields are combined with logical 'AND'."
input uuid_comparison_exp {
    _eq: uuid
    _gt: uuid
    _gte: uuid
    _in: [uuid!]
    _is_null: Boolean
    _lt: uuid
    _lte: uuid
    _neq: uuid
    _nin: [uuid!]
}
